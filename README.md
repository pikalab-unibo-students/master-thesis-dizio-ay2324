<p align="center"><img src="assets/logo.svg"></p>
<p align="center"><a href="https://www.python.org/"><img src="https://img.shields.io/badge/python-3670A0?style=flate&logo=python&logoColor=ffdd54"></a>   <a href="https://conventionalcommits.org"><img src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-%23FE5196?logo=conventionalcommits"></a></p>

# FairLib - Python Library for Fairness Metrics and Processing

This library provides a set of tools for measuring and improving fairness in machine learning models, covering a variety of fairness metrics, pre-processing, in-processing, and post-processing techniques.

[Complete Workflow Example Notebook](examples/demo_core_lib.ipynb)

## Library functionality
The library will provide some fairness metrics to perform various analyses. Plus a number of pre-processing, in-processing and post-processing algorithms.

### Fairness Metrics
- Statistical Parity Difference - [Example Notebook](examples/demo_statistical_parity_difference.ipynb)
- Disparate Impact
- Equal Opportunity Difference - [Example Notebook](examples/demo_equality_of_opportunity.ipynb)
- Average Absolute Odds Difference

### Pre-Processing Techniques
- Disparate Impact Remover
- LFR (Learning Fair Representations) - [Example Notebook](examples/demo_lfr.ipynb)
- Optim Preprocessing
- Reweighing

### In-Processing Techniques
- FaUCI - [Example Notebook](examples/demo_fauci.ipynb)
- Adversarial Debiasing
- Prejudice Remover
- Meta-Fair Classifier

### Post-Processing Techniques
- Equalized Odds
- Calibrated Equalized Odds
- Reject Option Classification

## Project Structure

Overview of the project structure:

```bash
<root directory>
├── fairlib/               # Main package for the project
│   ├── __init__.py        # Package marker
│   ├── metrics/           # Fairness metrics implementations
│   ├── preprocessing/     # Pre-processing techniques for fairness
│   ├── inprocessing/      # In-processing debiasing algorithms
│   └── postprocessing/    # Post-processing fairness methods
├── tests/                 # Unit tests for the library
│   ├── metrics/           # Unit tests for fairness metrics
│   ├── preprocessing/     # Unit tests for pre-processing methods
│   ├── inprocessing/      # Unit tests for in-processing techniques
│   └── postprocessing/    # Unit tests for post-processing methods
├── examples/             # Jupyter notebooks with examples
├── .github/               # GitHub workflows for CI/CD
│   └── workflows/
│       ├── test.yml       # Run tests on multiple Python versions
│       └── deploy.yml     # Deploy to PyPI if tests succeed
├── pyproject.toml         # Project configuration file managed by Poetry
├── LICENSE                # License file (Apache 2.0 by default)
├── README.md              # Project documentation (this file)
├── renovate.json          # Configuration of Renovate bot, for automatic dependency updates
├── requirements.txt       # Only declares a dependency on Poetry. DO NOT EDIT THIS FILE
└── release.config.js      # Script to release on PyPi, and GitHub via semantic-release
```

### Restore dev dependencies

1. Install Poetry if you don't have it yet
```bash
pip install -r requirements.txt
```

2. Install the project's dependencies
```bash
poetry install
```

### Run unit tests
```bash
poetry run poe test
```

> Tests are automatically run in CI, on all pushes on all branches.
> There, tests are executed on multiple OS (Win, Mac, Ubuntu) and on multiple Python versions.
