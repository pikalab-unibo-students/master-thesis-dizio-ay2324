{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaUCI: Fairness Under Constrained Injection.\n",
    "FaUCI (Fairness Under Constrained Injection) is an in-processing fairness algorithm that incorporates fairness constraints directly into the model training process through regularization.\n",
    "\n",
    "This algorithm works by adding fairness-specific regularization terms to the loss function, which penalize the model when it produces unfair predictions. The model learns to balance between predictive accuracy and fairness during training.\n",
    "\n",
    "The key idea is to use regularization to impose fairness constraints:\n",
    "- The model is trained with a standard loss function (e.g., BCE loss by classification).\n",
    "- A regularization term for fairness is added to the loss function to penalize unfair predictions\n",
    "- The strength of the fairness constraint is controlled by a regularization weight parameter\n",
    "\n",
    "FaUCI supports several fairness metrics as regularization targets:\n",
    "- Statistical Parity Difference (SPD): Ensures similar prediction rates across demographic groups\n",
    "- Disparate Impact (DI): Ensures that the ratio of positive prediction rates across groups is close to 1\n",
    "\n",
    "The regularization weight controls the trade-off between fairness and accuracy:\n",
    "- weight = 0: No fairness constraint (standard model)\n",
    "- weight > 0: Increasing values impose stronger fairness constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:38.713812Z",
     "start_time": "2025-05-15T08:41:38.711159Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory of the project to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:41.323821Z",
     "start_time": "2025-05-15T08:41:38.847557Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import openml\n",
    "\n",
    "from fairlib import DataFrame\n",
    "from fairlib.inprocessing import Fauci\n",
    "from fairlib.metrics import statistical_parity_difference, disparate_impact\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing the Adult Dataset.\n",
    "We will use the Adult dataset from OpenML, which contains demographic information and predicts whether an individual earns more than $50K per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:41.447028Z",
     "start_time": "2025-05-15T08:41:41.327802Z"
    }
   },
   "outputs": [],
   "source": [
    "adult_dataset = openml.datasets.get_dataset(179)\n",
    "adult_X, _, _, _ = adult_dataset.get_data(dataset_format=\"dataframe\")\n",
    "\n",
    "adult_X.rename(columns={'class': 'income'}, inplace=True)\n",
    "\n",
    "adult = DataFrame(adult_X)\n",
    "\n",
    "adult.targets = 'income'\n",
    "adult.sensitive = ['sex']\n",
    "\n",
    "adult.drop(columns=[\"fnlwgt\"], inplace=True)\n",
    "\n",
    "label_maps = {}\n",
    "\n",
    "for col in adult.columns:\n",
    "    if adult[col].dtype == 'object' or adult[col].dtype == 'category':\n",
    "        adult[col], uniques = pd.factorize(adult[col])\n",
    "        label_maps[col] = uniques\n",
    "\n",
    "print(f\"Dataset Form: {adult.shape}\")\n",
    "print(f\"Target Column: {adult.targets}\")\n",
    "print(f\"Sensitive Attributes: {adult.sensitive}\")\n",
    "\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis.\n",
    "We examine the distribution of income versus sex to understand potential inequalities in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:41.627842Z",
     "start_time": "2025-05-15T08:41:41.533807Z"
    }
   },
   "outputs": [],
   "source": [
    "sex_labels = label_maps['sex'].tolist()\n",
    "income_labels = label_maps['income'].tolist()\n",
    "\n",
    "# Calculate the sex/income cross distribution.\n",
    "counts = adult.groupby('sex')['income'].value_counts().unstack()\n",
    "\n",
    "# Rename indexes and columns to make them readable\n",
    "counts.index = [sex_labels[i] for i in counts.index]\n",
    "counts.columns = [income_labels[i] for i in counts.columns]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts.plot(kind='bar', stacked=True)\n",
    "plt.title('Distribution of income by gender')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Income')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for the Model.\n",
    "We divide the dataset into training and test sets, and standardize the numerical characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:42.070643Z",
     "start_time": "2025-05-15T08:41:42.050383Z"
    }
   },
   "outputs": [],
   "source": [
    "X = adult.drop(columns=['income'])\n",
    "y = adult['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['age', 'education-num', 'capitalgain', 'capitalloss', 'hoursperweek']\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "sensitive_idx = X_train.columns.get_loc('sex')\n",
    "sensitive_train = X_train.iloc[:, sensitive_idx].values\n",
    "sensitive_test = X_test.iloc[:, sensitive_idx].values\n",
    "\n",
    "print(f\"Size of the training set: {X_train_tensor.shape}\")\n",
    "print(f\"Size of the test set: {X_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Baseline Model.\n",
    "Before implementing FaUCI, we train a baseline model to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:51.111832Z",
     "start_time": "2025-05-15T08:41:42.843355Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "base_model = BaseModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    base_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        outputs = base_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        accuracy = 100 * correct / total\n",
    "        avg_loss = epoch_loss / (len(X_train_tensor) // batch_size)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Base Model.\n",
    "We evaluate the performance of the base model in terms of both accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:41:51.125275Z",
     "start_time": "2025-05-15T08:41:51.116757Z"
    }
   },
   "outputs": [],
   "source": [
    "SENSITIVE_COL_NAME=\"sex\"\n",
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_base = base_model(X_test_tensor)\n",
    "    y_pred_base_binary = (y_pred_base > 0.5).float()\n",
    "\n",
    "    X_test_baseline = X_test_tensor.detach().cpu().numpy()\n",
    "    y_pred_baseline = y_pred_base_binary.detach().cpu().numpy()\n",
    "\n",
    "    baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "    print(f\"Baseline model accuracy: {baseline_accuracy:.4f}\")\n",
    "\n",
    "    baseline_spd = statistical_parity_difference(y_pred_baseline, X_test[SENSITIVE_COL_NAME])\n",
    "    baseline_di = disparate_impact(y_pred_baseline, X_test[SENSITIVE_COL_NAME])\n",
    "\n",
    "    print(f\"Statistical Parity Difference (SPD): {baseline_spd}\")\n",
    "    print(f\"Disparate Impact (DI): {baseline_di}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of FaUCI.\n",
    "We now implement FaUCI with different regularization weights to explore the trade-off between accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:44:05.062549Z",
     "start_time": "2025-05-15T08:41:51.148345Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_weights = [0.0, 0.1, 0.3, 0.5, 0.6, 0.8]\n",
    "\n",
    "accuracies = {}\n",
    "spd_values = {}\n",
    "di_values = {}\n",
    "\n",
    "for weight in reg_weights:\n",
    "    print(f\" FaUCI training with regularization weight: {weight}\")\n",
    "\n",
    "    model = BaseModel()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    fauci_model = Fauci(\n",
    "        torchModel=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=nn.BCELoss(),\n",
    "        fairness_regularization=\"spd\",  # Statistical Parity Difference\n",
    "        regularization_weight=weight\n",
    "    )\n",
    "\n",
    "    train_data = DataFrame(X_train_scaled)\n",
    "    train_data['income'] = y_train.values\n",
    "    train_data.targets = 'income'\n",
    "    train_data.sensitive = ['sex']\n",
    "\n",
    "    fauci_model.fit(train_data, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "\n",
    "    base_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_base = fauci_model.predict(X_test_tensor)\n",
    "        y_pred_base_binary = (y_pred_base > 0.5).float()\n",
    "\n",
    "        y_pred_baseline = y_pred_base_binary.detach().cpu().numpy()\n",
    "\n",
    "        baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "        print(f\"Baseline model accuracy: {baseline_accuracy:.4f}\")\n",
    "\n",
    "        baseline_spd = statistical_parity_difference(y_pred_baseline, X_test[SENSITIVE_COL_NAME])\n",
    "        baseline_di = disparate_impact(y_pred_baseline, X_test[SENSITIVE_COL_NAME])\n",
    "\n",
    "        print(f\"Statistical Parity Difference (SPD): {baseline_spd}\")\n",
    "        print(f\"Disparate Impact (DI): {baseline_di}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
