{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 17:19:13.575211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734365953.595081 4047885 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734365953.601130 4047885 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 17:19:13.621173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:fairlib:Using Keras backend: TENSORFLOW\n",
      "INFO:fairlib:fairlib loaded\n"
     ]
    }
   ],
   "source": [
    "import fairlib as fl\n",
    "from fairlib.inprocessing import Fauci\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tests.data_generator import biased_dataset_people_height\n",
    "\n",
    "from fairlib import keras\n",
    "keras.utils.set_random_seed(423)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = biased_dataset_people_height(binary=True)\n",
    "X = dataset.drop(columns=['class'], axis=1).values\n",
    "y = dataset['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179.461261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.989611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163.323137</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.553938</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.535270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>141.536912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>191.528178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>142.457990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>142.033719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>174.174044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          height  class  male\n",
       "0     179.461261      1     1\n",
       "1     160.989611      0     1\n",
       "2     163.323137      0     1\n",
       "3     171.553938      1     1\n",
       "4     116.535270      0     0\n",
       "...          ...    ...   ...\n",
       "9995  141.536912      0     1\n",
       "9996  191.528178      1     1\n",
       "9997  142.457990      0     0\n",
       "9998  142.033719      0     1\n",
       "9999  174.174044      1     1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(class=0, male=0) -> -0.319767577003299\n",
       "(class=0, male=1) -> 0.319767577003299\n",
       "(class=1, male=0) -> 0.319767577003299\n",
       "(class=1, male=1) -> -0.319767577003299"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.statistical_parity_difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.targets = \"class\"\n",
    "dataset.sensitive = 'male' # fauci currently supports only one sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>male</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187.330040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177.595211</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.488624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.407366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162.339374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>168.896291</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>173.782952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>143.182428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>122.936792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>188.849322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          height  male  class\n",
       "0     187.330040     1      1\n",
       "1     177.595211     1      1\n",
       "2     150.488624     1      0\n",
       "3     161.407366     0      1\n",
       "4     162.339374     0      1\n",
       "...          ...   ...    ...\n",
       "1995  168.896291     0      1\n",
       "1996  173.782952     0      1\n",
       "1997  143.182428     1      0\n",
       "1998  122.936792     0      0\n",
       "1999  188.849322     1      1\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = fl.DataFrame(X_test, columns=['height', 'male'])\n",
    "test_data['male'] = test_data['male'].astype(int)\n",
    "test_data['class'] = y_test\n",
    "test_data.targets = \"class\"\n",
    "test_data.sensitive = 'male'\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_params = dict(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "W = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 17:19:15.950043: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "unwrapped = create_model()\n",
    "unwrapped.compile(**learning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed = Fauci(create_model(), regularizer=None, regularization_weight=0.0, **learning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inprocessing_spd = Fauci(create_model(), regularizer='sp', regularization_weight=W, **learning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inprocessing_di = Fauci(create_model(), regularizer='di', regularization_weight=W, **learning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 500\n",
    "VALIDATION_SPLIT=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwrapped.fit(X_train.astype(float), y_train.astype(float), epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed.fit(dataset, converting_to_type=float, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 31ms/step - accuracy: 0.4438 - loss: 0.5108 - val_accuracy: 0.5590 - val_loss: 0.2163\n",
      "Epoch 2/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5620 - loss: 0.1885 - val_accuracy: 0.4410 - val_loss: 0.1585\n",
      "Epoch 3/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4633 - loss: 0.1494 - val_accuracy: 0.5590 - val_loss: 0.1356\n",
      "Epoch 4/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6135 - loss: 0.1321 - val_accuracy: 0.6577 - val_loss: 0.1311\n",
      "Epoch 5/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7016 - loss: 0.1311 - val_accuracy: 0.7320 - val_loss: 0.1305\n",
      "Epoch 6/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7144 - loss: 0.1306 - val_accuracy: 0.6827 - val_loss: 0.1293\n",
      "Epoch 7/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6834 - loss: 0.1294 - val_accuracy: 0.7827 - val_loss: 0.1290\n",
      "Epoch 8/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7192 - loss: 0.1290 - val_accuracy: 0.8907 - val_loss: 0.1286\n",
      "Epoch 9/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7687 - loss: 0.1286 - val_accuracy: 0.8920 - val_loss: 0.1281\n",
      "Epoch 10/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7717 - loss: 0.1281 - val_accuracy: 0.8857 - val_loss: 0.1276\n",
      "Epoch 11/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7705 - loss: 0.1275 - val_accuracy: 0.8510 - val_loss: 0.1271\n",
      "Epoch 12/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7669 - loss: 0.1270 - val_accuracy: 0.8360 - val_loss: 0.1266\n",
      "Epoch 13/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7637 - loss: 0.1265 - val_accuracy: 0.8183 - val_loss: 0.1262\n",
      "Epoch 14/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7601 - loss: 0.1259 - val_accuracy: 0.8043 - val_loss: 0.1257\n",
      "Epoch 15/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7559 - loss: 0.1254 - val_accuracy: 0.7943 - val_loss: 0.1252\n",
      "Epoch 16/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7529 - loss: 0.1249 - val_accuracy: 0.7897 - val_loss: 0.1247\n",
      "Epoch 17/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7465 - loss: 0.1243 - val_accuracy: 0.7893 - val_loss: 0.1243\n",
      "Epoch 18/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7428 - loss: 0.1238 - val_accuracy: 0.7930 - val_loss: 0.1238\n",
      "Epoch 19/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7411 - loss: 0.1232 - val_accuracy: 0.8010 - val_loss: 0.1232\n",
      "Epoch 20/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7421 - loss: 0.1227 - val_accuracy: 0.8090 - val_loss: 0.1227\n",
      "Epoch 21/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7392 - loss: 0.1221 - val_accuracy: 0.8283 - val_loss: 0.1221\n",
      "Epoch 22/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7393 - loss: 0.1216 - val_accuracy: 0.8440 - val_loss: 0.1215\n",
      "Epoch 23/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7384 - loss: 0.1210 - val_accuracy: 0.8653 - val_loss: 0.1208\n",
      "Epoch 24/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7392 - loss: 0.1204 - val_accuracy: 0.8863 - val_loss: 0.1202\n",
      "Epoch 25/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7422 - loss: 0.1199 - val_accuracy: 0.8820 - val_loss: 0.1196\n",
      "Epoch 26/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7389 - loss: 0.1193 - val_accuracy: 0.8667 - val_loss: 0.1189\n",
      "Epoch 27/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7313 - loss: 0.1187 - val_accuracy: 0.8500 - val_loss: 0.1183\n",
      "Epoch 28/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7254 - loss: 0.1182 - val_accuracy: 0.8333 - val_loss: 0.1177\n",
      "Epoch 29/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7234 - loss: 0.1177 - val_accuracy: 0.8160 - val_loss: 0.1171\n",
      "Epoch 30/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7180 - loss: 0.1171 - val_accuracy: 0.7973 - val_loss: 0.1165\n",
      "Epoch 31/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7154 - loss: 0.1166 - val_accuracy: 0.7827 - val_loss: 0.1159\n",
      "Epoch 32/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7137 - loss: 0.1161 - val_accuracy: 0.7727 - val_loss: 0.1153\n",
      "Epoch 33/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7108 - loss: 0.1155 - val_accuracy: 0.7650 - val_loss: 0.1148\n",
      "Epoch 34/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7075 - loss: 0.1150 - val_accuracy: 0.7560 - val_loss: 0.1142\n",
      "Epoch 35/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7044 - loss: 0.1145 - val_accuracy: 0.7473 - val_loss: 0.1137\n",
      "Epoch 36/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7016 - loss: 0.1141 - val_accuracy: 0.7410 - val_loss: 0.1132\n",
      "Epoch 37/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7005 - loss: 0.1136 - val_accuracy: 0.7333 - val_loss: 0.1127\n",
      "Epoch 38/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6995 - loss: 0.1131 - val_accuracy: 0.7283 - val_loss: 0.1122\n",
      "Epoch 39/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6975 - loss: 0.1127 - val_accuracy: 0.7243 - val_loss: 0.1118\n",
      "Epoch 40/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6987 - loss: 0.1122 - val_accuracy: 0.7190 - val_loss: 0.1113\n",
      "Epoch 41/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6980 - loss: 0.1118 - val_accuracy: 0.7150 - val_loss: 0.1109\n",
      "Epoch 42/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6981 - loss: 0.1113 - val_accuracy: 0.7130 - val_loss: 0.1104\n",
      "Epoch 43/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6990 - loss: 0.1109 - val_accuracy: 0.7113 - val_loss: 0.1101\n",
      "Epoch 44/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6981 - loss: 0.1105 - val_accuracy: 0.7093 - val_loss: 0.1096\n",
      "Epoch 45/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6986 - loss: 0.1101 - val_accuracy: 0.7067 - val_loss: 0.1093\n",
      "Epoch 46/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6988 - loss: 0.1097 - val_accuracy: 0.7060 - val_loss: 0.1089\n",
      "Epoch 47/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6994 - loss: 0.1093 - val_accuracy: 0.7053 - val_loss: 0.1085\n",
      "Epoch 48/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7000 - loss: 0.1089 - val_accuracy: 0.7020 - val_loss: 0.1081\n",
      "Epoch 49/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7003 - loss: 0.1085 - val_accuracy: 0.7010 - val_loss: 0.1078\n",
      "Epoch 50/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7009 - loss: 0.1081 - val_accuracy: 0.7007 - val_loss: 0.1074\n",
      "Epoch 51/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7012 - loss: 0.1077 - val_accuracy: 0.7010 - val_loss: 0.1071\n",
      "Epoch 52/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7022 - loss: 0.1074 - val_accuracy: 0.7010 - val_loss: 0.1067\n",
      "Epoch 53/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7023 - loss: 0.1070 - val_accuracy: 0.7007 - val_loss: 0.1064\n",
      "Epoch 54/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7026 - loss: 0.1067 - val_accuracy: 0.6993 - val_loss: 0.1060\n",
      "Epoch 55/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7025 - loss: 0.1063 - val_accuracy: 0.6997 - val_loss: 0.1057\n",
      "Epoch 56/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7034 - loss: 0.1060 - val_accuracy: 0.6993 - val_loss: 0.1054\n",
      "Epoch 57/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7039 - loss: 0.1056 - val_accuracy: 0.6993 - val_loss: 0.1051\n",
      "Epoch 58/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7041 - loss: 0.1053 - val_accuracy: 0.7000 - val_loss: 0.1048\n",
      "Epoch 59/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7049 - loss: 0.1049 - val_accuracy: 0.7003 - val_loss: 0.1045\n",
      "Epoch 60/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7056 - loss: 0.1046 - val_accuracy: 0.7007 - val_loss: 0.1041\n",
      "Epoch 61/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7058 - loss: 0.1043 - val_accuracy: 0.7007 - val_loss: 0.1038\n",
      "Epoch 62/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7064 - loss: 0.1040 - val_accuracy: 0.7017 - val_loss: 0.1035\n",
      "Epoch 63/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7079 - loss: 0.1036 - val_accuracy: 0.7020 - val_loss: 0.1032\n",
      "Epoch 64/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7085 - loss: 0.1033 - val_accuracy: 0.7023 - val_loss: 0.1029\n",
      "Epoch 65/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7091 - loss: 0.1030 - val_accuracy: 0.7030 - val_loss: 0.1027\n",
      "Epoch 66/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7093 - loss: 0.1027 - val_accuracy: 0.7033 - val_loss: 0.1024\n",
      "Epoch 67/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7103 - loss: 0.1024 - val_accuracy: 0.7033 - val_loss: 0.1021\n",
      "Epoch 68/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7121 - loss: 0.1021 - val_accuracy: 0.7053 - val_loss: 0.1018\n",
      "Epoch 69/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7135 - loss: 0.1018 - val_accuracy: 0.7057 - val_loss: 0.1015\n",
      "Epoch 70/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7150 - loss: 0.1015 - val_accuracy: 0.7087 - val_loss: 0.1012\n",
      "Epoch 71/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7165 - loss: 0.1012 - val_accuracy: 0.7087 - val_loss: 0.1009\n",
      "Epoch 72/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7174 - loss: 0.1009 - val_accuracy: 0.7093 - val_loss: 0.1006\n",
      "Epoch 73/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7190 - loss: 0.1006 - val_accuracy: 0.7100 - val_loss: 0.1004\n",
      "Epoch 74/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7193 - loss: 0.1003 - val_accuracy: 0.7107 - val_loss: 0.1001\n",
      "Epoch 75/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7200 - loss: 0.1000 - val_accuracy: 0.7117 - val_loss: 0.0998\n",
      "Epoch 76/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7210 - loss: 0.0997 - val_accuracy: 0.7127 - val_loss: 0.0995\n",
      "Epoch 77/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7236 - loss: 0.0995 - val_accuracy: 0.7127 - val_loss: 0.0993\n",
      "Epoch 78/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7244 - loss: 0.0992 - val_accuracy: 0.7133 - val_loss: 0.0990\n",
      "Epoch 79/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7254 - loss: 0.0989 - val_accuracy: 0.7140 - val_loss: 0.0987\n",
      "Epoch 80/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7272 - loss: 0.0986 - val_accuracy: 0.7160 - val_loss: 0.0984\n",
      "Epoch 81/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7290 - loss: 0.0983 - val_accuracy: 0.7163 - val_loss: 0.0982\n",
      "Epoch 82/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7293 - loss: 0.0981 - val_accuracy: 0.7173 - val_loss: 0.0979\n",
      "Epoch 83/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7301 - loss: 0.0978 - val_accuracy: 0.7177 - val_loss: 0.0976\n",
      "Epoch 84/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7334 - loss: 0.0975 - val_accuracy: 0.7187 - val_loss: 0.0974\n",
      "Epoch 85/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7339 - loss: 0.0973 - val_accuracy: 0.7187 - val_loss: 0.0971\n",
      "Epoch 86/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7343 - loss: 0.0970 - val_accuracy: 0.7190 - val_loss: 0.0969\n",
      "Epoch 87/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7350 - loss: 0.0967 - val_accuracy: 0.7200 - val_loss: 0.0966\n",
      "Epoch 88/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7371 - loss: 0.0965 - val_accuracy: 0.7207 - val_loss: 0.0963\n",
      "Epoch 89/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7385 - loss: 0.0962 - val_accuracy: 0.7213 - val_loss: 0.0961\n",
      "Epoch 90/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7396 - loss: 0.0960 - val_accuracy: 0.7220 - val_loss: 0.0958\n",
      "Epoch 91/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7402 - loss: 0.0957 - val_accuracy: 0.7233 - val_loss: 0.0956\n",
      "Epoch 92/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7423 - loss: 0.0954 - val_accuracy: 0.7237 - val_loss: 0.0953\n",
      "Epoch 93/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7429 - loss: 0.0952 - val_accuracy: 0.7253 - val_loss: 0.0951\n",
      "Epoch 94/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7443 - loss: 0.0949 - val_accuracy: 0.7257 - val_loss: 0.0948\n",
      "Epoch 95/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7449 - loss: 0.0946 - val_accuracy: 0.7283 - val_loss: 0.0946\n",
      "Epoch 96/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7461 - loss: 0.0944 - val_accuracy: 0.7287 - val_loss: 0.0943\n",
      "Epoch 97/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7468 - loss: 0.0941 - val_accuracy: 0.7300 - val_loss: 0.0940\n",
      "Epoch 98/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7476 - loss: 0.0939 - val_accuracy: 0.7310 - val_loss: 0.0938\n",
      "Epoch 99/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7482 - loss: 0.0936 - val_accuracy: 0.7327 - val_loss: 0.0936\n",
      "Epoch 100/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7489 - loss: 0.0934 - val_accuracy: 0.7333 - val_loss: 0.0933\n",
      "Epoch 101/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7493 - loss: 0.0931 - val_accuracy: 0.7337 - val_loss: 0.0931\n",
      "Epoch 102/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7503 - loss: 0.0929 - val_accuracy: 0.7353 - val_loss: 0.0928\n",
      "Epoch 103/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7513 - loss: 0.0927 - val_accuracy: 0.7363 - val_loss: 0.0926\n",
      "Epoch 104/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7522 - loss: 0.0924 - val_accuracy: 0.7380 - val_loss: 0.0923\n",
      "Epoch 105/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7534 - loss: 0.0922 - val_accuracy: 0.7383 - val_loss: 0.0921\n",
      "Epoch 106/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7547 - loss: 0.0919 - val_accuracy: 0.7393 - val_loss: 0.0918\n",
      "Epoch 107/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7553 - loss: 0.0917 - val_accuracy: 0.7430 - val_loss: 0.0916\n",
      "Epoch 108/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7568 - loss: 0.0914 - val_accuracy: 0.7433 - val_loss: 0.0913\n",
      "Epoch 109/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7581 - loss: 0.0912 - val_accuracy: 0.7443 - val_loss: 0.0911\n",
      "Epoch 110/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7596 - loss: 0.0909 - val_accuracy: 0.7447 - val_loss: 0.0909\n",
      "Epoch 111/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7612 - loss: 0.0907 - val_accuracy: 0.7460 - val_loss: 0.0906\n",
      "Epoch 112/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7621 - loss: 0.0905 - val_accuracy: 0.7480 - val_loss: 0.0904\n",
      "Epoch 113/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7633 - loss: 0.0902 - val_accuracy: 0.7487 - val_loss: 0.0901\n",
      "Epoch 114/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7655 - loss: 0.0900 - val_accuracy: 0.7493 - val_loss: 0.0899\n",
      "Epoch 115/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7661 - loss: 0.0897 - val_accuracy: 0.7517 - val_loss: 0.0897\n",
      "Epoch 116/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7672 - loss: 0.0895 - val_accuracy: 0.7530 - val_loss: 0.0894\n",
      "Epoch 117/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7694 - loss: 0.0893 - val_accuracy: 0.7537 - val_loss: 0.0892\n",
      "Epoch 118/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7704 - loss: 0.0890 - val_accuracy: 0.7540 - val_loss: 0.0890\n",
      "Epoch 119/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7719 - loss: 0.0888 - val_accuracy: 0.7553 - val_loss: 0.0887\n",
      "Epoch 120/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7726 - loss: 0.0886 - val_accuracy: 0.7553 - val_loss: 0.0885\n",
      "Epoch 121/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7731 - loss: 0.0883 - val_accuracy: 0.7567 - val_loss: 0.0882\n",
      "Epoch 122/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7749 - loss: 0.0881 - val_accuracy: 0.7577 - val_loss: 0.0880\n",
      "Epoch 123/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7759 - loss: 0.0879 - val_accuracy: 0.7593 - val_loss: 0.0878\n",
      "Epoch 124/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7772 - loss: 0.0876 - val_accuracy: 0.7603 - val_loss: 0.0875\n",
      "Epoch 125/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7787 - loss: 0.0874 - val_accuracy: 0.7607 - val_loss: 0.0873\n",
      "Epoch 126/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7804 - loss: 0.0872 - val_accuracy: 0.7617 - val_loss: 0.0871\n",
      "Epoch 127/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7816 - loss: 0.0869 - val_accuracy: 0.7633 - val_loss: 0.0868\n",
      "Epoch 128/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7824 - loss: 0.0867 - val_accuracy: 0.7647 - val_loss: 0.0866\n",
      "Epoch 129/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7834 - loss: 0.0865 - val_accuracy: 0.7663 - val_loss: 0.0864\n",
      "Epoch 130/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7848 - loss: 0.0863 - val_accuracy: 0.7663 - val_loss: 0.0862\n",
      "Epoch 131/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7863 - loss: 0.0860 - val_accuracy: 0.7673 - val_loss: 0.0859\n",
      "Epoch 132/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7864 - loss: 0.0858 - val_accuracy: 0.7697 - val_loss: 0.0857\n",
      "Epoch 133/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7875 - loss: 0.0856 - val_accuracy: 0.7697 - val_loss: 0.0855\n",
      "Epoch 134/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7885 - loss: 0.0854 - val_accuracy: 0.7713 - val_loss: 0.0853\n",
      "Epoch 135/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7891 - loss: 0.0851 - val_accuracy: 0.7730 - val_loss: 0.0850\n",
      "Epoch 136/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7899 - loss: 0.0849 - val_accuracy: 0.7733 - val_loss: 0.0848\n",
      "Epoch 137/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7903 - loss: 0.0847 - val_accuracy: 0.7753 - val_loss: 0.0846\n",
      "Epoch 138/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7921 - loss: 0.0845 - val_accuracy: 0.7753 - val_loss: 0.0844\n",
      "Epoch 139/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7937 - loss: 0.0843 - val_accuracy: 0.7757 - val_loss: 0.0842\n",
      "Epoch 140/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7951 - loss: 0.0840 - val_accuracy: 0.7790 - val_loss: 0.0839\n",
      "Epoch 141/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7977 - loss: 0.0838 - val_accuracy: 0.7790 - val_loss: 0.0837\n",
      "Epoch 142/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7985 - loss: 0.0836 - val_accuracy: 0.7807 - val_loss: 0.0835\n",
      "Epoch 143/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7986 - loss: 0.0834 - val_accuracy: 0.7817 - val_loss: 0.0833\n",
      "Epoch 144/200\n",
      "\u001b[1m 7/14\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7845 - loss: 0.0837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minprocessing_spd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverting_to_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/fairlib/inprocessing/fauci.py:248\u001b[0m, in \u001b[0;36mFaUCI.fit\u001b[0;34m(self, x, y, converting_to_type, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m compilation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__loss\n\u001b[1;32m    247\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompilation_params)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/fairlib/processing.py:105\u001b[0m, in \u001b[0;36mDataFrameAwareProcessorWrapper._fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Work/Studenti/master-thesis-dizio-ay2324/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inprocessing_spd.fit(dataset, converting_to_type=float, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4340 - loss: 12.7167 - val_accuracy: 0.4410 - val_loss: 12.0144\n",
      "Epoch 2/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 11.9152 - val_accuracy: 0.4410 - val_loss: 11.2306\n",
      "Epoch 3/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 11.1285 - val_accuracy: 0.4410 - val_loss: 10.4624\n",
      "Epoch 4/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 10.3576 - val_accuracy: 0.4410 - val_loss: 9.7097\n",
      "Epoch 5/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 9.6021 - val_accuracy: 0.4410 - val_loss: 8.9714\n",
      "Epoch 6/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 8.8608 - val_accuracy: 0.4410 - val_loss: 8.2463\n",
      "Epoch 7/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 8.1325 - val_accuracy: 0.4410 - val_loss: 7.5331\n",
      "Epoch 8/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 7.4159 - val_accuracy: 0.4410 - val_loss: 6.8304\n",
      "Epoch 9/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 6.7095 - val_accuracy: 0.4410 - val_loss: 6.1368\n",
      "Epoch 10/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 6.0119 - val_accuracy: 0.4410 - val_loss: 5.4509\n",
      "Epoch 11/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4340 - loss: 5.3218 - val_accuracy: 0.4410 - val_loss: 4.7712\n",
      "Epoch 12/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4340 - loss: 4.6375 - val_accuracy: 0.4410 - val_loss: 4.0963\n",
      "Epoch 13/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 3.9578 - val_accuracy: 0.4410 - val_loss: 3.4246\n",
      "Epoch 14/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 3.2808 - val_accuracy: 0.4410 - val_loss: 2.7546\n",
      "Epoch 15/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4340 - loss: 2.6052 - val_accuracy: 0.4410 - val_loss: 2.0845\n",
      "Epoch 16/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4340 - loss: 1.9291 - val_accuracy: 0.4410 - val_loss: 1.4134\n",
      "Epoch 17/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4356 - loss: 1.2613 - val_accuracy: 0.6733 - val_loss: 0.9240\n",
      "Epoch 18/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5980 - loss: 0.9449 - val_accuracy: 0.5590 - val_loss: 0.9494\n",
      "Epoch 19/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6173 - loss: 0.9346 - val_accuracy: 0.4880 - val_loss: 0.9299\n",
      "Epoch 20/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5325 - loss: 0.9293 - val_accuracy: 0.7070 - val_loss: 0.9238\n",
      "Epoch 21/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6751 - loss: 0.9241 - val_accuracy: 0.6687 - val_loss: 0.9238\n",
      "Epoch 22/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6951 - loss: 0.9237 - val_accuracy: 0.7913 - val_loss: 0.9238\n",
      "Epoch 23/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7667 - loss: 0.9239 - val_accuracy: 0.7057 - val_loss: 0.9236\n",
      "Epoch 24/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6952 - loss: 0.9236 - val_accuracy: 0.7153 - val_loss: 0.9235\n",
      "Epoch 25/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7136 - loss: 0.9235 - val_accuracy: 0.7243 - val_loss: 0.9235\n",
      "Epoch 26/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7124 - loss: 0.9235 - val_accuracy: 0.7157 - val_loss: 0.9234\n",
      "Epoch 27/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7087 - loss: 0.9234 - val_accuracy: 0.7197 - val_loss: 0.9233\n",
      "Epoch 28/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7121 - loss: 0.9234 - val_accuracy: 0.7197 - val_loss: 0.9232\n",
      "Epoch 29/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7107 - loss: 0.9233 - val_accuracy: 0.7197 - val_loss: 0.9232\n",
      "Epoch 30/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7114 - loss: 0.9232 - val_accuracy: 0.7200 - val_loss: 0.9231\n",
      "Epoch 31/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7115 - loss: 0.9231 - val_accuracy: 0.7203 - val_loss: 0.9230\n",
      "Epoch 32/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7116 - loss: 0.9231 - val_accuracy: 0.7210 - val_loss: 0.9229\n",
      "Epoch 33/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7127 - loss: 0.9230 - val_accuracy: 0.7210 - val_loss: 0.9229\n",
      "Epoch 34/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7128 - loss: 0.9229 - val_accuracy: 0.7227 - val_loss: 0.9228\n",
      "Epoch 35/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7133 - loss: 0.9228 - val_accuracy: 0.7227 - val_loss: 0.9227\n",
      "Epoch 36/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7139 - loss: 0.9227 - val_accuracy: 0.7233 - val_loss: 0.9226\n",
      "Epoch 37/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7142 - loss: 0.9227 - val_accuracy: 0.7240 - val_loss: 0.9225\n",
      "Epoch 38/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7141 - loss: 0.9226 - val_accuracy: 0.7243 - val_loss: 0.9225\n",
      "Epoch 39/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7146 - loss: 0.9225 - val_accuracy: 0.7247 - val_loss: 0.9224\n",
      "Epoch 40/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7158 - loss: 0.9224 - val_accuracy: 0.7253 - val_loss: 0.9223\n",
      "Epoch 41/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7159 - loss: 0.9223 - val_accuracy: 0.7253 - val_loss: 0.9222\n",
      "Epoch 42/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7160 - loss: 0.9222 - val_accuracy: 0.7260 - val_loss: 0.9221\n",
      "Epoch 43/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7161 - loss: 0.9222 - val_accuracy: 0.7263 - val_loss: 0.9220\n",
      "Epoch 44/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7161 - loss: 0.9221 - val_accuracy: 0.7270 - val_loss: 0.9219\n",
      "Epoch 45/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7163 - loss: 0.9220 - val_accuracy: 0.7273 - val_loss: 0.9218\n",
      "Epoch 46/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7166 - loss: 0.9219 - val_accuracy: 0.7280 - val_loss: 0.9218\n",
      "Epoch 47/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7166 - loss: 0.9218 - val_accuracy: 0.7283 - val_loss: 0.9217\n",
      "Epoch 48/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7169 - loss: 0.9217 - val_accuracy: 0.7287 - val_loss: 0.9216\n",
      "Epoch 49/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7171 - loss: 0.9216 - val_accuracy: 0.7297 - val_loss: 0.9215\n",
      "Epoch 50/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7171 - loss: 0.9215 - val_accuracy: 0.7297 - val_loss: 0.9214\n",
      "Epoch 51/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7174 - loss: 0.9214 - val_accuracy: 0.7297 - val_loss: 0.9213\n",
      "Epoch 52/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7178 - loss: 0.9213 - val_accuracy: 0.7300 - val_loss: 0.9212\n",
      "Epoch 53/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7182 - loss: 0.9212 - val_accuracy: 0.7307 - val_loss: 0.9211\n",
      "Epoch 54/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7182 - loss: 0.9211 - val_accuracy: 0.7320 - val_loss: 0.9210\n",
      "Epoch 55/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7182 - loss: 0.9210 - val_accuracy: 0.7320 - val_loss: 0.9209\n",
      "Epoch 56/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7191 - loss: 0.9209 - val_accuracy: 0.7323 - val_loss: 0.9208\n",
      "Epoch 57/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7199 - loss: 0.9208 - val_accuracy: 0.7327 - val_loss: 0.9207\n",
      "Epoch 58/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7200 - loss: 0.9207 - val_accuracy: 0.7333 - val_loss: 0.9206\n",
      "Epoch 59/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7200 - loss: 0.9206 - val_accuracy: 0.7333 - val_loss: 0.9205\n",
      "Epoch 60/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7202 - loss: 0.9205 - val_accuracy: 0.7333 - val_loss: 0.9204\n",
      "Epoch 61/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7209 - loss: 0.9204 - val_accuracy: 0.7340 - val_loss: 0.9203\n",
      "Epoch 62/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7220 - loss: 0.9203 - val_accuracy: 0.7353 - val_loss: 0.9202\n",
      "Epoch 63/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7221 - loss: 0.9202 - val_accuracy: 0.7353 - val_loss: 0.9201\n",
      "Epoch 64/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7229 - loss: 0.9201 - val_accuracy: 0.7360 - val_loss: 0.9200\n",
      "Epoch 65/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7232 - loss: 0.9200 - val_accuracy: 0.7373 - val_loss: 0.9199\n",
      "Epoch 66/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7237 - loss: 0.9199 - val_accuracy: 0.7380 - val_loss: 0.9198\n",
      "Epoch 67/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7239 - loss: 0.9198 - val_accuracy: 0.7383 - val_loss: 0.9197\n",
      "Epoch 68/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7243 - loss: 0.9197 - val_accuracy: 0.7393 - val_loss: 0.9195\n",
      "Epoch 69/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7245 - loss: 0.9196 - val_accuracy: 0.7403 - val_loss: 0.9194\n",
      "Epoch 70/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7248 - loss: 0.9195 - val_accuracy: 0.7407 - val_loss: 0.9193\n",
      "Epoch 71/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7255 - loss: 0.9194 - val_accuracy: 0.7410 - val_loss: 0.9192\n",
      "Epoch 72/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7264 - loss: 0.9193 - val_accuracy: 0.7413 - val_loss: 0.9191\n",
      "Epoch 73/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7267 - loss: 0.9191 - val_accuracy: 0.7417 - val_loss: 0.9190\n",
      "Epoch 74/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7268 - loss: 0.9190 - val_accuracy: 0.7420 - val_loss: 0.9189\n",
      "Epoch 75/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7277 - loss: 0.9189 - val_accuracy: 0.7423 - val_loss: 0.9188\n",
      "Epoch 76/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7280 - loss: 0.9188 - val_accuracy: 0.7430 - val_loss: 0.9187\n",
      "Epoch 77/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7280 - loss: 0.9187 - val_accuracy: 0.7433 - val_loss: 0.9185\n",
      "Epoch 78/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7283 - loss: 0.9186 - val_accuracy: 0.7433 - val_loss: 0.9184\n",
      "Epoch 79/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7286 - loss: 0.9185 - val_accuracy: 0.7437 - val_loss: 0.9183\n",
      "Epoch 80/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7292 - loss: 0.9183 - val_accuracy: 0.7440 - val_loss: 0.9182\n",
      "Epoch 81/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7295 - loss: 0.9182 - val_accuracy: 0.7450 - val_loss: 0.9181\n",
      "Epoch 82/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7297 - loss: 0.9181 - val_accuracy: 0.7457 - val_loss: 0.9180\n",
      "Epoch 83/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7302 - loss: 0.9180 - val_accuracy: 0.7467 - val_loss: 0.9178\n",
      "Epoch 84/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7309 - loss: 0.9179 - val_accuracy: 0.7473 - val_loss: 0.9177\n",
      "Epoch 85/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7312 - loss: 0.9178 - val_accuracy: 0.7477 - val_loss: 0.9176\n",
      "Epoch 86/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7318 - loss: 0.9176 - val_accuracy: 0.7477 - val_loss: 0.9175\n",
      "Epoch 87/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7323 - loss: 0.9175 - val_accuracy: 0.7480 - val_loss: 0.9174\n",
      "Epoch 88/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7325 - loss: 0.9174 - val_accuracy: 0.7487 - val_loss: 0.9172\n",
      "Epoch 89/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7328 - loss: 0.9173 - val_accuracy: 0.7493 - val_loss: 0.9171\n",
      "Epoch 90/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7333 - loss: 0.9172 - val_accuracy: 0.7497 - val_loss: 0.9170\n",
      "Epoch 91/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7334 - loss: 0.9170 - val_accuracy: 0.7503 - val_loss: 0.9169\n",
      "Epoch 92/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7335 - loss: 0.9169 - val_accuracy: 0.7520 - val_loss: 0.9168\n",
      "Epoch 93/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7345 - loss: 0.9168 - val_accuracy: 0.7520 - val_loss: 0.9166\n",
      "Epoch 94/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7352 - loss: 0.9167 - val_accuracy: 0.7523 - val_loss: 0.9165\n",
      "Epoch 95/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7352 - loss: 0.9166 - val_accuracy: 0.7530 - val_loss: 0.9164\n",
      "Epoch 96/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7354 - loss: 0.9164 - val_accuracy: 0.7537 - val_loss: 0.9163\n",
      "Epoch 97/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7363 - loss: 0.9163 - val_accuracy: 0.7540 - val_loss: 0.9162\n",
      "Epoch 98/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7363 - loss: 0.9162 - val_accuracy: 0.7550 - val_loss: 0.9160\n",
      "Epoch 99/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7364 - loss: 0.9161 - val_accuracy: 0.7550 - val_loss: 0.9159\n",
      "Epoch 100/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7368 - loss: 0.9159 - val_accuracy: 0.7553 - val_loss: 0.9158\n",
      "Epoch 101/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7376 - loss: 0.9158 - val_accuracy: 0.7557 - val_loss: 0.9157\n",
      "Epoch 102/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7383 - loss: 0.9157 - val_accuracy: 0.7570 - val_loss: 0.9155\n",
      "Epoch 103/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7383 - loss: 0.9156 - val_accuracy: 0.7573 - val_loss: 0.9154\n",
      "Epoch 104/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7395 - loss: 0.9154 - val_accuracy: 0.7587 - val_loss: 0.9153\n",
      "Epoch 105/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7399 - loss: 0.9153 - val_accuracy: 0.7587 - val_loss: 0.9151\n",
      "Epoch 106/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7400 - loss: 0.9152 - val_accuracy: 0.7590 - val_loss: 0.9150\n",
      "Epoch 107/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7403 - loss: 0.9150 - val_accuracy: 0.7610 - val_loss: 0.9149\n",
      "Epoch 108/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7411 - loss: 0.9149 - val_accuracy: 0.7613 - val_loss: 0.9148\n",
      "Epoch 109/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7418 - loss: 0.9148 - val_accuracy: 0.7613 - val_loss: 0.9146\n",
      "Epoch 110/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7422 - loss: 0.9147 - val_accuracy: 0.7620 - val_loss: 0.9145\n",
      "Epoch 111/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7431 - loss: 0.9145 - val_accuracy: 0.7627 - val_loss: 0.9144\n",
      "Epoch 112/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7436 - loss: 0.9144 - val_accuracy: 0.7627 - val_loss: 0.9143\n",
      "Epoch 113/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7439 - loss: 0.9143 - val_accuracy: 0.7630 - val_loss: 0.9141\n",
      "Epoch 114/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7444 - loss: 0.9141 - val_accuracy: 0.7643 - val_loss: 0.9140\n",
      "Epoch 115/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7447 - loss: 0.9140 - val_accuracy: 0.7650 - val_loss: 0.9139\n",
      "Epoch 116/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7453 - loss: 0.9139 - val_accuracy: 0.7663 - val_loss: 0.9137\n",
      "Epoch 117/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7464 - loss: 0.9138 - val_accuracy: 0.7673 - val_loss: 0.9136\n",
      "Epoch 118/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7467 - loss: 0.9136 - val_accuracy: 0.7680 - val_loss: 0.9135\n",
      "Epoch 119/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7468 - loss: 0.9135 - val_accuracy: 0.7683 - val_loss: 0.9134\n",
      "Epoch 120/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7473 - loss: 0.9134 - val_accuracy: 0.7683 - val_loss: 0.9132\n",
      "Epoch 121/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7473 - loss: 0.9132 - val_accuracy: 0.7683 - val_loss: 0.9131\n",
      "Epoch 122/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7476 - loss: 0.9131 - val_accuracy: 0.7687 - val_loss: 0.9130\n",
      "Epoch 123/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7479 - loss: 0.9130 - val_accuracy: 0.7690 - val_loss: 0.9128\n",
      "Epoch 124/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7484 - loss: 0.9128 - val_accuracy: 0.7690 - val_loss: 0.9127\n",
      "Epoch 125/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7488 - loss: 0.9127 - val_accuracy: 0.7690 - val_loss: 0.9126\n",
      "Epoch 126/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7497 - loss: 0.9126 - val_accuracy: 0.7700 - val_loss: 0.9124\n",
      "Epoch 127/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7498 - loss: 0.9124 - val_accuracy: 0.7703 - val_loss: 0.9123\n",
      "Epoch 128/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7499 - loss: 0.9123 - val_accuracy: 0.7717 - val_loss: 0.9122\n",
      "Epoch 129/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.9122 - val_accuracy: 0.7720 - val_loss: 0.9120\n",
      "Epoch 130/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7502 - loss: 0.9120 - val_accuracy: 0.7723 - val_loss: 0.9119\n",
      "Epoch 131/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7510 - loss: 0.9119 - val_accuracy: 0.7730 - val_loss: 0.9118\n",
      "Epoch 132/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7512 - loss: 0.9118 - val_accuracy: 0.7730 - val_loss: 0.9116\n",
      "Epoch 133/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7518 - loss: 0.9116 - val_accuracy: 0.7733 - val_loss: 0.9115\n",
      "Epoch 134/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7523 - loss: 0.9115 - val_accuracy: 0.7740 - val_loss: 0.9114\n",
      "Epoch 135/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7537 - loss: 0.9114 - val_accuracy: 0.7743 - val_loss: 0.9112\n",
      "Epoch 136/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7538 - loss: 0.9112 - val_accuracy: 0.7750 - val_loss: 0.9111\n",
      "Epoch 137/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7549 - loss: 0.9111 - val_accuracy: 0.7763 - val_loss: 0.9110\n",
      "Epoch 138/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7558 - loss: 0.9110 - val_accuracy: 0.7780 - val_loss: 0.9109\n",
      "Epoch 139/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7564 - loss: 0.9108 - val_accuracy: 0.7783 - val_loss: 0.9107\n",
      "Epoch 140/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7567 - loss: 0.9107 - val_accuracy: 0.7793 - val_loss: 0.9106\n",
      "Epoch 141/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7567 - loss: 0.9106 - val_accuracy: 0.7797 - val_loss: 0.9105\n",
      "Epoch 142/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7570 - loss: 0.9104 - val_accuracy: 0.7797 - val_loss: 0.9103\n",
      "Epoch 143/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7573 - loss: 0.9103 - val_accuracy: 0.7807 - val_loss: 0.9102\n",
      "Epoch 144/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7575 - loss: 0.9102 - val_accuracy: 0.7810 - val_loss: 0.9101\n",
      "Epoch 145/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7582 - loss: 0.9100 - val_accuracy: 0.7813 - val_loss: 0.9099\n",
      "Epoch 146/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7587 - loss: 0.9099 - val_accuracy: 0.7813 - val_loss: 0.9098\n",
      "Epoch 147/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7588 - loss: 0.9098 - val_accuracy: 0.7820 - val_loss: 0.9097\n",
      "Epoch 148/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7588 - loss: 0.9096 - val_accuracy: 0.7830 - val_loss: 0.9095\n",
      "Epoch 149/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7590 - loss: 0.9095 - val_accuracy: 0.7833 - val_loss: 0.9094\n",
      "Epoch 150/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7608 - loss: 0.9093 - val_accuracy: 0.7840 - val_loss: 0.9093\n",
      "Epoch 151/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7608 - loss: 0.9092 - val_accuracy: 0.7840 - val_loss: 0.9091\n",
      "Epoch 152/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7613 - loss: 0.9091 - val_accuracy: 0.7847 - val_loss: 0.9090\n",
      "Epoch 153/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7620 - loss: 0.9089 - val_accuracy: 0.7850 - val_loss: 0.9089\n",
      "Epoch 154/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7625 - loss: 0.9088 - val_accuracy: 0.7853 - val_loss: 0.9087\n",
      "Epoch 155/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7624 - loss: 0.9087 - val_accuracy: 0.7857 - val_loss: 0.9086\n",
      "Epoch 156/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7625 - loss: 0.9085 - val_accuracy: 0.7867 - val_loss: 0.9085\n",
      "Epoch 157/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7624 - loss: 0.9084 - val_accuracy: 0.7877 - val_loss: 0.9083\n",
      "Epoch 158/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7628 - loss: 0.9083 - val_accuracy: 0.7883 - val_loss: 0.9082\n",
      "Epoch 159/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7631 - loss: 0.9081 - val_accuracy: 0.7897 - val_loss: 0.9081\n",
      "Epoch 160/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7631 - loss: 0.9080 - val_accuracy: 0.7913 - val_loss: 0.9079\n",
      "Epoch 161/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7634 - loss: 0.9079 - val_accuracy: 0.7920 - val_loss: 0.9078\n",
      "Epoch 162/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7639 - loss: 0.9077 - val_accuracy: 0.7927 - val_loss: 0.9077\n",
      "Epoch 163/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7650 - loss: 0.9076 - val_accuracy: 0.7933 - val_loss: 0.9075\n",
      "Epoch 164/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7655 - loss: 0.9074 - val_accuracy: 0.7943 - val_loss: 0.9074\n",
      "Epoch 165/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7655 - loss: 0.9073 - val_accuracy: 0.7943 - val_loss: 0.9073\n",
      "Epoch 166/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7659 - loss: 0.9072 - val_accuracy: 0.7960 - val_loss: 0.9071\n",
      "Epoch 167/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7666 - loss: 0.9070 - val_accuracy: 0.7977 - val_loss: 0.9070\n",
      "Epoch 168/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7667 - loss: 0.9069 - val_accuracy: 0.7987 - val_loss: 0.9069\n",
      "Epoch 169/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7667 - loss: 0.9068 - val_accuracy: 0.7993 - val_loss: 0.9067\n",
      "Epoch 170/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7680 - loss: 0.9066 - val_accuracy: 0.7997 - val_loss: 0.9066\n",
      "Epoch 171/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7681 - loss: 0.9065 - val_accuracy: 0.8010 - val_loss: 0.9065\n",
      "Epoch 172/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7682 - loss: 0.9064 - val_accuracy: 0.8017 - val_loss: 0.9064\n",
      "Epoch 173/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7683 - loss: 0.9062 - val_accuracy: 0.8023 - val_loss: 0.9062\n",
      "Epoch 174/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7683 - loss: 0.9061 - val_accuracy: 0.8027 - val_loss: 0.9061\n",
      "Epoch 175/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7683 - loss: 0.9060 - val_accuracy: 0.8037 - val_loss: 0.9060\n",
      "Epoch 176/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7686 - loss: 0.9058 - val_accuracy: 0.8053 - val_loss: 0.9058\n",
      "Epoch 177/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7686 - loss: 0.9057 - val_accuracy: 0.8057 - val_loss: 0.9057\n",
      "Epoch 178/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7687 - loss: 0.9055 - val_accuracy: 0.8067 - val_loss: 0.9056\n",
      "Epoch 179/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7692 - loss: 0.9054 - val_accuracy: 0.8073 - val_loss: 0.9054\n",
      "Epoch 180/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7692 - loss: 0.9053 - val_accuracy: 0.8083 - val_loss: 0.9053\n",
      "Epoch 181/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7693 - loss: 0.9051 - val_accuracy: 0.8090 - val_loss: 0.9052\n",
      "Epoch 182/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7698 - loss: 0.9050 - val_accuracy: 0.8103 - val_loss: 0.9051\n",
      "Epoch 183/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7703 - loss: 0.9049 - val_accuracy: 0.8110 - val_loss: 0.9049\n",
      "Epoch 184/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7703 - loss: 0.9047 - val_accuracy: 0.8123 - val_loss: 0.9048\n",
      "Epoch 185/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7712 - loss: 0.9046 - val_accuracy: 0.8133 - val_loss: 0.9047\n",
      "Epoch 186/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7719 - loss: 0.9045 - val_accuracy: 0.8140 - val_loss: 0.9045\n",
      "Epoch 187/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7718 - loss: 0.9043 - val_accuracy: 0.8153 - val_loss: 0.9044\n",
      "Epoch 188/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7719 - loss: 0.9042 - val_accuracy: 0.8160 - val_loss: 0.9043\n",
      "Epoch 189/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7720 - loss: 0.9041 - val_accuracy: 0.8180 - val_loss: 0.9042\n",
      "Epoch 190/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7725 - loss: 0.9039 - val_accuracy: 0.8190 - val_loss: 0.9040\n",
      "Epoch 191/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7733 - loss: 0.9038 - val_accuracy: 0.8197 - val_loss: 0.9039\n",
      "Epoch 192/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7736 - loss: 0.9037 - val_accuracy: 0.8207 - val_loss: 0.9038\n",
      "Epoch 193/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7738 - loss: 0.9035 - val_accuracy: 0.8227 - val_loss: 0.9036\n",
      "Epoch 194/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7740 - loss: 0.9034 - val_accuracy: 0.8230 - val_loss: 0.9035\n",
      "Epoch 195/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7746 - loss: 0.9033 - val_accuracy: 0.8233 - val_loss: 0.9034\n",
      "Epoch 196/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7759 - loss: 0.9031 - val_accuracy: 0.8243 - val_loss: 0.9033\n",
      "Epoch 197/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7760 - loss: 0.9030 - val_accuracy: 0.8250 - val_loss: 0.9031\n",
      "Epoch 198/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7759 - loss: 0.9029 - val_accuracy: 0.8267 - val_loss: 0.9030\n",
      "Epoch 199/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7760 - loss: 0.9027 - val_accuracy: 0.8273 - val_loss: 0.9029\n",
      "Epoch 200/200\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7767 - loss: 0.9026 - val_accuracy: 0.8287 - val_loss: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7447243e8ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inprocessing_di.fit(dataset, converting_to_type=float, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "y_pred_unwrapped = unwrapped.predict(X_test)\n",
    "y_pred_unprocessed = unprocessed.predict(test_data)\n",
    "y_pred_spd = inprocessing_spd.predict(test_data)\n",
    "y_pred_di = inprocessing_di.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_unwrapped = (y_pred_unwrapped > 0.5).astype(int)\n",
    "y_pred_unprocessed = (y_pred_unprocessed > 0.5).astype(int)\n",
    "y_pred_spd = (y_pred_spd > 0.5).astype(int)\n",
    "y_pred_di = (y_pred_di > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== unwrapped ==========\n",
      "accuracy: 0.8235\n",
      "statistical_parity_difference: 0.7035543424026298\n",
      "disparate_impact: 0.25011105619130447\n",
      "========== unprocessed ==========\n",
      "accuracy: 0.7915\n",
      "statistical_parity_difference: 0.7362038096915265\n",
      "disparate_impact: 0.19436771715251103\n",
      "========== spd ==========\n",
      "accuracy: 0.828\n",
      "statistical_parity_difference: 0.652760412080655\n",
      "disparate_impact: 0.23968247456514605\n",
      "========== di ==========\n",
      "accuracy: 0.818\n",
      "statistical_parity_difference: 0.7377124240556485\n",
      "disparate_impact: 0.25133145083461417\n"
     ]
    }
   ],
   "source": [
    "experiments = ['unwrapped', 'unprocessed', 'spd', 'di']\n",
    "accuracies = []\n",
    "spds = []\n",
    "dis = []\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(\"=\" * 10, experiment, \"=\" * 10)\n",
    "    data = test_data.copy()\n",
    "    expected = data['class']\n",
    "    data['class'] = locals()[f'y_pred_{experiment}']\n",
    "    case = {'class': 1, 'male': 0}\n",
    "    accuracies.append(accuracy_score(expected, data['class']))\n",
    "    print(\"accuracy:\", accuracies[-1])\n",
    "    spds.append(abs(data.statistical_parity_difference()[case]))\n",
    "    print(\"statistical_parity_difference:\", spds[-1])\n",
    "    dis.append(abs(data.disparate_impact()[case]))\n",
    "    print(\"disparate_impact:\", dis[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfAklEQVR4nO3deVgVdf//8dcBZRMBlVXjFnclFQwSl9tAxSWX0kzNFpDUb2WUSVlqKS530qKmmWmZS4ulmeatuWUoLUqae5lamlspqKngUqAwvz/8eW5PgAIyHNHn47rmujyf+czMe85hhNeZmc9YDMMwBAAAAAAASpyDvQsAAAAAAOBmRegGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAlEkWi0WjRo2ydxnX7cMPP1T9+vVVvnx5eXl52bscwGrOnDmyWCw6cOCAvUsBgDKN0A0AZdS+ffv02GOPqWbNmnJxcZGHh4datmypyZMn66+//rJ3eSiE3bt3q2/fvqpVq5ZmzJihd999t1DLPf/887JYLOrdu7fJFd4azp49q8TERDVs2FAVKlRQlSpVFBoaqkGDBunIkSPWfqNGjZLFYrFObm5uCg4O1ksvvaTMzExrv8th9fLk4uKiqlWrqkOHDnrzzTd15swZe+ymafJ7X/71r3+pa9eumj17trKysvIs07dvX7m7u9uhWgAofeXsXQAAoOiWLVumnj17ytnZWTExMWrYsKGys7P13XffaciQIdq5c2ehA1xZ9ddff6lcubL9aywlJUW5ubmaPHmyateuXahlDMPQJ598oqCgIC1dulRnzpxRxYoVTa705nXhwgXddddd2r17t2JjY/XUU0/p7Nmz2rlzpz7++GN1795dVatWtVlm2rRpcnd319mzZ/Xll1/q5Zdf1po1a7Ru3TpZLBZrvzFjxqhGjRq6cOGC0tLSlJKSomeeeUYTJ07UkiVL1Lhx49LeXVNdfl+ysrL0xx9/aNWqVXr00Uc1adIkffHFFwoMDLR3iQBgF2X7rxUAuAXt379fDzzwgKpXr641a9YoICDAOu/JJ5/U3r17tWzZMjtWaJ7c3FxlZ2fLxcVFLi4u9i7nuh07dkySinRZeUpKin7//XetWbNGHTp00KJFixQbG2tShdfn/PnzcnNzs3cZV7V48WJt3bpVc+fO1YMPPmgz7++//1Z2dnaeZe6//355e3tLkh5//HH16NFDixYt0vfff6/mzZtb+919990KDw+3vh42bJjWrFmjLl266J577tGuXbvk6upq0p6VvivfF0kaOXKk5s6dq5iYGPXs2VPff/+9HasDAPvh8nIAKGNee+01nT17VjNnzrQJ3JfVrl1bgwYNsr6+ePGixo4dq1q1asnZ2VlBQUEaPnx4nks+g4KC1KVLF6WkpCg8PFyurq5q1KiRUlJSJEmLFi1So0aN5OLiorCwMG3dutVm+cuXi/7222/q0KGDKlSooKpVq2rMmDEyDMOm7/jx49WiRQtVqVJFrq6uCgsL02effZZnXywWi+Lj4zV37lzdfvvtcnZ21sqVK63zrryn+8yZM3rmmWcUFBQkZ2dn+fr6ql27dtqyZYvNOhcsWKCwsDC5urrK29tbDz/8sP7444989+WPP/5Qt27d5O7uLh8fHz333HPKyckp4JOx9fbbb1trrlq1qp588kmdPn3a5v1OTEyUJPn4+BT6HvW5c+cqODhYrVu3VnR0tObOnZtvvz/++EP9+vVT1apV5ezsrBo1auiJJ56wCZGnT5/W4MGDre/ZbbfdppiYGJ04cUJSwff0pqSkyGKxWH82JCkqKkoNGzbU5s2bddddd8nNzU3Dhw+XJP33v/9V586drbXUqlVLY8eOzfe93LBhgzp16qRKlSqpQoUKaty4sSZPnixJmj17tiwWS56fPUkaN26cHB0d83yW17Jv3z5JUsuWLfPMu3zbxrW0adNG0qUvxArTd8SIETp48KA++uijItV62ezZs9WmTRv5+vrK2dlZwcHBmjZtWp5+l4/p7777Tk2bNpWLi4tq1qypDz74IE/fnTt3qk2bNnJ1ddVtt92m//znP8rNzS1WfVd66KGH1L9/f23YsEGrV6++7vUBQFlE6AaAMmbp0qWqWbOmWrRoUaj+/fv318iRI3XHHXfojTfeUGRkpJKSkvTAAw/k6bt37149+OCD6tq1q5KSknTq1Cl17dpVc+fO1eDBg/Xwww9r9OjR2rdvn3r16pXnj/KcnBx17NhRfn5+eu211xQWFqbExERruLxs8uTJatKkicaMGaNx48apXLly6tmzZ75n6NesWaPBgwerd+/emjx5soKCgvLdz8cff1zTpk1Tjx499Pbbb+u5556Tq6urdu3aZe0zZ84c9erVS46OjkpKStKAAQO0aNEi/fvf/7YJxJf3pUOHDqpSpYrGjx+vyMhITZgwoVCX7Y8aNUpPPvmkqlatqgkTJqhHjx5655131L59e124cEGSNGnSJHXv3l3SpctyP/zwQ913331XXW9WVpYWLlyoPn36SJL69OmjNWvWKC0tzabfkSNH1LRpU82bN0+9e/fWm2++qUceeURff/21zp8/L+nSfcytWrXSlClT1L59e02ePFmPP/64du/erd9///2a+5ifP//8U3fffbdCQ0M1adIktW7dWtKl993d3V0JCQmaPHmywsLCNHLkSA0dOtRm+dWrV+uuu+7Szz//rEGDBmnChAlq3bq1vvjiC0mXzqS6urrm+0XD3LlzFRUVpWrVqhWp5urVq0uSPvjggzxfDhXW5eBepUqVQvV/5JFHJElffvllsbY3bdo0Va9eXcOHD9eECRMUGBiogQMHaurUqXn67t27V/fff7/atWunCRMmqFKlSurbt6927txp7ZOWlqbWrVtr27ZtGjp0qJ555hl98MEH1i87rtf17i8AlHkGAKDMyMjIMCQZ9957b6H6b9u2zZBk9O/f36b9ueeeMyQZa9assbZVr17dkGSsX7/e2rZq1SpDkuHq6mocPHjQ2v7OO+8Ykoy1a9da22JjYw1JxlNPPWVty83NNTp37mw4OTkZx48ft7afP3/epp7s7GyjYcOGRps2bWzaJRkODg7Gzp078+ybJCMxMdH62tPT03jyyScLfC+ys7MNX19fo2HDhsZff/1lbf/iiy8MScbIkSPz7MuYMWNs1tGkSRMjLCyswG0YhmEcO3bMcHJyMtq3b2/k5ORY29966y1DkjFr1ixrW2JioiHJ5r25ms8++8yQZPz666+GYRhGZmam4eLiYrzxxhs2/WJiYgwHBwfjhx9+yLOO3NxcwzAMY+TIkYYkY9GiRQX2mT17tiHJ2L9/v838tWvX5vn8IyMjDUnG9OnT86zvn5+3YRjGY489Zri5uRl///23YRiGcfHiRaNGjRpG9erVjVOnTuVbj2EYRp8+fYyqVavavLdbtmwxJBmzZ8/Os51rOX/+vFGvXj1DklG9enWjb9++xsyZM4309PQ8fS9/Xnv27DGOHz9u7N+/33jnnXcMZ2dnw8/Pzzh37pxhGP973/J7/y/z9PQ0mjRpUuR6L9f8Tx06dDBq1qxp03b5mP7mm2+sbceOHTOcnZ2NZ5991tr2zDPPGJKMDRs22PTz9PTM9/P/p2v9HJ86dcqQZHTv3t3aFhsba1SoUOGq6wWAmwVnugGgDLk8QnJhB85avny5JCkhIcGm/dlnn5WkPGeWg4ODbe5JjYiIkHTpkth//etfedp/++23PNuMj4+3/vvy5eHZ2dn66quvrO1X3sd66tQpZWRkqFWrVnkuBZekyMhIBQcHX2NPL90XvWHDBpvRpq+0adMmHTt2TAMHDrS5H7xz586qX79+vmfZH3/8cZvXrVq1ynefr/TVV18pOztbzzzzjBwc/vdrdsCAAfLw8Liu++3nzp2r8PBw66BrFStWVOfOnW3O/Obm5mrx4sXq2rWrzf3El10e6GvhwoUKCQmxnm3Pr09ROTs7Ky4uLk/7lZ/3mTNndOLECbVq1Urnz5/X7t27JUlbt27V/v379cwzz+S5x/3KemJiYnTkyBGtXbvW2jZ37ly5urqqR48eRa7Z1dVVGzZs0JAhQyRdOivfr18/BQQE6Kmnnsp35O169erJx8dHNWrU0GOPPabatWtr2bJlRbp/3d3dvdijmF/5fmZkZOjEiROKjIzUb7/9poyMDJu+wcHBatWqlfW1j4+P6tWrZ/NzvHz5cjVr1kxNmza16ffQQw8Vq75/ujxK+c02ajsAFBahGwDKkMv3lxb2j9eDBw/KwcEhz8jY/v7+8vLy0sGDB23arwzWkuTp6SlJeUYdvtx+6tQpm3YHBwfVrFnTpq1u3bqSZHNf8BdffKFmzZrJxcVFlStXlo+Pj6ZNm5YnMEhSjRo1rrWbki7d6/7TTz8pMDBQTZs21ahRo2yCxeV9rVevXp5l69evn+e9cHFxkY+Pj01bpUqV8uzzPxW0HScnJ9WsWTPPdgrr9OnTWr58uSIjI7V3717r1LJlS23atEm//PKLJOn48ePKzMxUw4YNr7q+ffv2XbNPUVWrVk1OTk552nfu3Knu3bvL09NTHh4e8vHx0cMPPyxJ1s/88iXa16qpXbt2CggIsH7RkJubq08++UT33ntvsUdx9/T01GuvvaYDBw7owIEDmjlzpurVq6e33npLY8eOzdN/4cKFWr16tVJSUrR371799NNPCgsLK9I2z549W+x6161bp+joaFWoUEFeXl7y8fGx3j//z2Pon8e0lPfn+ODBg6pTp06efvkdK8Vx9uxZSYX/shAAbjaEbgAoQzw8PFS1alX99NNPRVqusGcuHR0di9RuFOMe2G+//Vb33HOPXFxc9Pbbb2v58uVavXq1HnzwwXzXV9jRnXv16qXffvtNU6ZMUdWqVfX666/r9ttv14oVK4pco1TwPtvLggULlJWVpQkTJqhOnTrW6fJVDAUNqHY9Cvq5KWgwufw+q9OnTysyMlLbt2/XmDFjtHTpUq1evVqvvvqqJBV5sC5HR0c9+OCDWrhwof7++2+tXbtWR44csYb461W9enU9+uijWrdunby8vPJ9X++66y5FR0crMjJStWrVKvI2fv/9d2VkZBT6MXFX2rdvn9q2basTJ05o4sSJWrZsmVavXq3BgwdLyvt+luSxW1yX/78qzv4CwM2A0A0AZUyXLl20b98+paamXrNv9erVlZubq19//dWmPT09XadPn7YOIlVScnNz81x+ffkM7OUB0BYuXCgXFxfrM3zvvvtuRUdHl8j2AwICNHDgQC1evFj79+9XlSpV9PLLL0v634BZe/bsybPcnj17Suy9KGg72dnZ2r9/f7G3M3fuXDVs2FALFizIM0VHR+vjjz+WdOmyYA8Pj2t+MVOrVq1r9qlUqZIk5Rlkrihn61NSUvTnn39qzpw5GjRokLp06aLo6Gjruq+sR1KhvlCKiYlRZmamli5dqrlz58rHx0cdOnQodE2FUalSJdWqVUtHjx4t0fVK0ocffihJxap56dKlysrK0pIlS/TYY4+pU6dOio6Ovq5Hj1WvXj3P/xFS/sdKcVzP/gLAzYDQDQBlzPPPP68KFSqof//+Sk9PzzN/37591lGHO3XqJOnSSNlXmjhxoqRL9zOXtLfeesv6b8Mw9NZbb6l8+fJq27atpEtn3iwWi83Z0gMHDmjx4sXF3mZOTk6ey2p9fX1VtWpV6z254eHh8vX11fTp023u012xYoV27dpVYu9FdHS0nJyc9Oabb9qcTZw5c6YyMjKKtZ3Dhw/rm2++Ua9evXT//ffnmeLi4rR3715t2LBBDg4O6tatm5YuXapNmzblWdflmnr06KHt27fr888/L7DP5SD8zTffWOfl5OQUagT3yy6fab3yvcjOztbbb79t0++OO+5QjRo1NGnSpDwh/59nZRs3bqzGjRvrvffe08KFC/XAAw+oXLlyha7pStu3b7c+Iu1KBw8e1M8//1xil1hftmbNGo0dO1Y1atQo1j3T+b2fGRkZmj17drFr6tSpk77//ntt3LjR2nb8+PESuXri448/1nvvvafmzZtb/w8AgFtN8X5DAQDsplatWvr444/Vu3dvNWjQQDExMWrYsKGys7O1fv16LViwQH379pUkhYSEKDY2Vu+++671Mt+NGzfq/fffV7du3ayPdCopLi4uWrlypWJjYxUREaEVK1Zo2bJlGj58uPX+6M6dO2vixInq2LGjHnzwQR07dkxTp05V7dq1tWPHjmJt98yZM7rtttt0//33KyQkRO7u7vrqq6/0ww8/aMKECZKk8uXL69VXX1VcXJwiIyPVp08fpaenWx9Ddvny3Ovl4+OjYcOGafTo0erYsaPuuece7dmzR2+//bbuvPPOYl0G/fHHH8swDN1zzz35zu/UqZPKlSunuXPnKiIiQuPGjdOXX36pyMhI/d///Z8aNGigo0ePasGCBfruu+/k5eWlIUOG6LPPPlPPnj316KOPKiwsTCdPntSSJUs0ffp0hYSE6Pbbb1ezZs00bNgwnTx5UpUrV9a8efN08eLFQtfeokULVapUSbGxsXr66adlsVj04Ycf5gnSDg4OmjZtmrp27arQ0FDFxcUpICBAu3fv1s6dO7Vq1Sqb/jExMXruueckKd/3NCUlRa1bt1ZiYuJVn3++evVqJSYm6p577lGzZs2sz5qfNWuWsrKyCvXs9IKsWLFCu3fv1sWLF5Wenq41a9Zo9erVql69upYsWWIzoN+BAwdUo0YNxcbGas6cOQWus3379nJyclLXrl312GOP6ezZs5oxY4Z8fX2LfVb++eef14cffqiOHTtq0KBBqlChgt59911Vr169SMfkZ599Jnd3d2VnZ+uPP/7QqlWrtG7dOoWEhGjBggXFqg0Abgr2GTQdAHC9fvnlF2PAgAFGUFCQ4eTkZFSsWNFo2bKlMWXKFOtjmAzDMC5cuGCMHj3aqFGjhlG+fHkjMDDQGDZsmE0fw7j0eKHOnTvn2Y6kPI/i2r9/vyHJeP31161tlx8BtG/fPqN9+/aGm5ub4efnZyQmJto83skwDGPmzJlGnTp1DGdnZ6N+/frG7NmzrY8duta2r5x3+ZFhWVlZxpAhQ4yQkBCjYsWKRoUKFYyQkBDj7bffzrPc/PnzjSZNmhjOzs5G5cqVjYceesj4/fffbfoU9Dij/GosyFtvvWXUr1/fKF++vOHn52c88cQTeR6FVdhHhjVq1Mj417/+ddU+UVFRhq+vr3HhwgXDMAzj4MGDRkxMjOHj42M4OzsbNWvWNJ588kkjKyvLusyff/5pxMfHG9WqVTOcnJyM2267zYiNjTVOnDhh7bNv3z4jOjra+lis4cOHG6tXr873kWG33357vrWtW7fOaNasmeHq6mpUrVrVeP75562Po7tyHYZhGN99953Rrl076+fYuHFjY8qUKXnWefToUcPR0dGoW7duvttcunRpgY8wu9Jvv/1mjBw50mjWrJnh6+trlCtXzvDx8TE6d+5s80g9wyj853X5kWGXJycnJ8Pf399o166dMXnyZCMzMzPPMj/++KMhyRg6dOhV120YhrFkyRKjcePGhouLixEUFGS8+uqrxqxZs/I83qugYzoyMtKIjIy0aduxY4cRGRlpuLi4GNWqVTPGjh1rzJw5s0iPDLs8ubi4GLfddpvRpUsXY9asWXn+rzEMHhkG4NZiMYxSHEkDAHDT6tu3rz777DPrSMWAmU6cOKGAgACNHDlSI0aMyDP/+eef1yeffKK9e/fK2dnZDhUWzdtvv63nn39e+/btk5+fn73LAQCUIO7pBgAAZc6cOXOUk5OjRx55JN/5a9eu1YgRI8pE4JYu1fv0008TuAHgJsQ93QAAoMxYs2aNfv75Z7388svq1q2bdVT8f/rhhx9Kt7DrxD3PAHDzInQDAIAyY8yYMVq/fr1atmypKVOm2LscAACuiXu6AQAAAAAwCfd0AwAAAABgEkI3AAAAAAAmueXu6c7NzdWRI0dUsWJFWSwWe5cDAAAAACiDDMPQmTNnVLVqVTk4FHw++5YL3UeOHFFgYKC9ywAAAAAA3AQOHz6s2267rcD5t1zorlixoqRLb4yHh4edqwEAAAAAlEWZmZkKDAy0ZsyC3HKh+/Il5R4eHoRuAAAAAMB1udZtywykBgAAAACASQjdAAAAAACYhNANAAAAAIBJbrl7ugEAAACgNOXm5io7O9veZaCIypcvL0dHx+teD6EbAAAAAEySnZ2t/fv3Kzc3196loBi8vLzk7+9/zcHSrobQDQAAAAAmMAxDR48elaOjowIDA+XgwN29ZYVhGDp//ryOHTsmSQoICCj2ugjdAAAAAGCCixcv6vz586patarc3NzsXQ6KyNXVVZJ07Ngx+fr6FvtSc75qAQAAAAAT5OTkSJKcnJzsXAmK6/KXJRcuXCj2OgjdAAAAAGCi67kfGPZVEp8doRsAAAAAAJMQugEAAAAAMAmhGwAAAABKkcVSulNxpaamytHRUZ07dy65nb8FEboBAAAAAHnMnDlTTz31lL755hsdOXLEbnVkZ2fbbdslgdANAAAAALBx9uxZzZ8/X0888YQ6d+6sOXPm2MxfunSp7rzzTrm4uMjb21vdu3e3zsvKytILL7ygwMBAOTs7q3bt2po5c6Ykac6cOfLy8rJZ1+LFi20GLBs1apRCQ0P13nvvqUaNGnJxcZEkrVy5Uv/+97/l5eWlKlWqqEuXLtq3b5/Nun7//Xf16dNHlStXVoUKFRQeHq4NGzbowIEDcnBw0KZNm2z6T5o0SdWrV1dubu71vmUFInQDAAAAAGx8+umnql+/vurVq6eHH35Ys2bNkmEYkqRly5ape/fu6tSpk7Zu3ark5GQ1bdrUumxMTIw++eQTvfnmm9q1a5feeecdubu7F2n7e/fu1cKFC7Vo0SJt27ZNknTu3DklJCRo06ZNSk5OloODg7p3724NzGfPnlVkZKT++OMPLVmyRNu3b9fzzz+v3NxcBQUFKTo6WrNnz7bZzuzZs9W3b185OJgXjcuZtmYAAAAAQJk0c+ZMPfzww5Kkjh07KiMjQ19//bWioqL08ssv64EHHtDo0aOt/UNCQiRJv/zyiz799FOtXr1a0dHRkqSaNWsWefvZ2dn64IMP5OPjY23r0aOHTZ9Zs2bJx8dHP//8sxo2bKiPP/5Yx48f1w8//KDKlStLkmrXrm3t379/fz3++OOaOHGinJ2dtWXLFv3444/673//W+T6ioIz3QAAAAAAqz179mjjxo3q06ePJKlcuXLq3bu39RLxbdu2qW3btvkuu23bNjk6OioyMvK6aqhevbpN4JakX3/9VX369FHNmjXl4eGhoKAgSdKhQ4es227SpIk1cP9Tt27d5OjoqM8//1zSpUvdW7dubV2PWTjTDQAAAACwmjlzpi5evKiqVata2wzDkLOzs9566y25uroWuOzV5kmSg4OD9TL1yy5cuJCnX4UKFfK0de3aVdWrV9eMGTNUtWpV5ebmqmHDhtaB1q61bScnJ8XExGj27Nm677779PHHH2vy5MlXXaYkcKYbAAAAACBJunjxoj744ANNmDBB27Zts07bt29X1apV9cknn6hx48ZKTk7Od/lGjRopNzdXX3/9db7zfXx8dObMGZ07d87advme7av5888/tWfPHr300ktq27atGjRooFOnTtn0ady4sbZt26aTJ08WuJ7+/fvrq6++0ttvv62LFy/qvvvuu+a2rxdnugEAAAAAkqQvvvhCp06dUr9+/eTp6Wkzr0ePHpo5c6Zef/11tW3bVrVq1dIDDzygixcvavny5XrhhRcUFBSk2NhYPfroo3rzzTcVEhKigwcP6tixY+rVq5ciIiLk5uam4cOH6+mnn9aGDRvyjIyen0qVKqlKlSp69913FRAQoEOHDmno0KE2ffr06aNx48apW7duSkpKUkBAgLZu3aqqVauqefPmkqQGDRqoWbNmeuGFF/Too49e8+x4SeBMNwAAAABA0qVLy6Ojo/MEbulS6N60aZMqV66sBQsWaMmSJQoNDVWbNm20ceNGa79p06bp/vvv18CBA1W/fn0NGDDAema7cuXK+uijj7R8+XI1atRIn3zyiUaNGnXNuhwcHDRv3jxt3rxZDRs21ODBg/X666/b9HFyctKXX34pX19fderUSY0aNdIrr7wiR0dHm379+vVTdna2Hn300WK8Q0VnMf55Qf1NLjMzU56ensrIyJCHh4e9ywEAACXsike9lim31l9kwK3h77//1v79+22eNQ37Gzt2rBYsWKAdO3Zcs+/VPsPCZkvOdAMAAAAAbnpnz57VTz/9pLfeektPPfVUqW2X0A0AAAAAuOnFx8crLCxMUVFRpXZpucRAajc0Lo8DAAAAgJIxZ86cQg3aVtI40w0AAAAAgEkI3QAAAAAAmITLywEAAACUCm6fxK2IM90AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASRhIDQAAAABKkWV06Y4oZyQWfSS448ePa+TIkVq2bJnS09NVqVIlhYSEaOTIkWrZsqWCgoJ08OBBSZKbm5vq1aunYcOGqWfPnpKkUaNGafTo0ZIkR0dHeXl5KTg4WPfdd5+eeOIJOTs7l9wO3uDsfqZ76tSpCgoKkouLiyIiIrRx48ar9p80aZLq1asnV1dXBQYGavDgwfr7779LqVoAAAAAuPn16NFDW7du1fvvv69ffvlFS5YsUVRUlP78809rnzFjxujo0aPaunWr7rzzTvXu3Vvr16+3zr/99tt19OhRHTp0SGvXrlXPnj2VlJSkFi1a6MyZM/bYLbuw65nu+fPnKyEhQdOnT1dERIQmTZqkDh06aM+ePfL19c3T/+OPP9bQoUM1a9YstWjRQr/88ov69u0ri8WiiRMn2mEPAAAAAODmcvr0aX377bdKSUlRZGSkJKl69epq2rSpTb+KFSvK399f/v7+mjp1qj766CMtXbpULVq0kCSVK1dO/v7+kqSqVauqUaNGateunUJCQvTqq6/qP//5T+numJ3Y9Uz3xIkTNWDAAMXFxSk4OFjTp0+Xm5ubZs2alW//9evXq2XLlnrwwQcVFBSk9u3bq0+fPtc8Ow4AAAAAKBx3d3e5u7tr8eLFysrKKtQy5cqVU/ny5ZWdnX3VfvXr19fdd9+tRYsWlUSpZYLdQnd2drY2b96s6Ojo/xXj4KDo6Gilpqbmu0yLFi20efNma8j+7bfftHz5cnXq1KlUagYAAACAm125cuU0Z84cvf/++/Ly8lLLli01fPhw7dixI9/+2dnZSkpKUkZGhtq0aXPN9devX18HDhwo4apvXHYL3SdOnFBOTo78/Pxs2v38/JSWlpbvMg8++KDGjBmjf//73ypfvrxq1aqlqKgoDR8+vMDtZGVlKTMz02YCAAAAABSsR48eOnLkiJYsWaKOHTsqJSVFd9xxh+bMmWPt88ILL8jd3V1ubm569dVX9corr6hz587XXLdhGLJYSncwOXuy+0BqRZGSkqJx48bp7bff1pYtW7Ro0SItW7ZMY8eOLXCZpKQkeXp6WqfAwMBSrBgAAAAAyiYXFxe1a9dOI0aM0Pr169W3b18lJiZa5w8ZMkTbtm3T77//rlOnTumFF14o1Hp37dqlGjVqmFX2Dcduodvb21uOjo5KT0+3aU9PT7febP9PI0aM0COPPKL+/furUaNG6t69u8aNG6ekpCTl5ubmu8ywYcOUkZFhnQ4fPlzi+wIAAAAAN7vg4GCdO3fO+trb21u1a9eWv79/oc9c7969WytXrlSPHj3MKvOGY7fQ7eTkpLCwMCUnJ1vbcnNzlZycrObNm+e7zPnz5+XgYFuyo6OjpEuXKOTH2dlZHh4eNhMAAAAAIH9//vmn2rRpo48++kg7duzQ/v37tWDBAr322mu69957C72eixcvKi0tTUeOHNGPP/6oKVOmKDIyUqGhoRoyZIiJe3BjsesjwxISEhQbG6vw8HA1bdpUkyZN0rlz5xQXFydJiomJUbVq1ZSUlCRJ6tq1qyZOnKgmTZooIiJCe/fu1YgRI9S1a1dr+AYAAAAAFJ+7u7siIiL0xhtvaN++fbpw4YICAwM1YMCAq46n9U87d+5UQECAHB0d5enpqeDgYA0bNkxPPPGEnJ2dTdyDG4vFKOgUcSl566239PrrrystLU2hoaF68803FRERIUmKiopSUFCQ9Wb9ixcv6uWXX9aHH36oP/74Qz4+PuratatefvlleXl5FWp7mZmZ8vT0VEZGxg1/1rusji1g358oAMCtjt+fwI3rVjs+//77b+3fv181atSQi4tLyRaFUnG1z7Cw2dLuobu0EbrNd2v9ROFWxfEJ3Lg4PoEb1612fBK6y76SCN1lavRyAAAAAADKEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAlCaLpXSnIurbt68sFossFovKly8vPz8/tWvXTrNmzVJubq61X1BQkCZNmlSCb8zNidANAAAAALDRsWNHHT16VAcOHNCKFSvUunVrDRo0SF26dNHFixftXV6ZUs7eBQAAAAAAbizOzs7y9/eXJFWrVk133HGHmjVrprZt22rOnDnq37+/nSssOzjTDQAAAAC4pjZt2igkJESLFi2ydyllCqEbAAAAAFAo9evX14EDB+xdRplC6AYAAAAAFIphGLIUY3C2WxmhGwAAAABQKLt27VKNGjXsXUaZQugGAAAAAFzTmjVr9OOPP6pHjx72LqVMYfRyAAAAAICNrKwspaWlKScnR+np6Vq5cqWSkpLUpUsXxcTE2Lu8MoXQDQAAAACwsXLlSgUEBKhcuXKqVKmSQkJC9Oabbyo2NlYODlwwXRSEbgAAAAAoTYZh7wquas6cOZozZ841+zGKeeHwFQUAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAJjIuMEHTkPBSuKzI3QDAAAAgAkcHR0lSdnZ2XauBMV1/vx5SVL58uWLvQ4eGQYAAAAAJihXrpzc3Nx0/PhxlS9fnudblyGGYej8+fM6duyYvLy8rF+gFAehGwAAAABMYLFYFBAQoP379+vgwYP2LgfF4OXlJX9//+taB6EbAAAAAEzi5OSkOnXqcIl5GVS+fPnrOsN9GaEbAAAAAEzk4OAgFxcXe5cBOyF0AwAAAMBVWEZb7F1CsRmJjJxub4RuALiF8EcDAABA6WL4PAAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMckOE7qlTpyooKEguLi6KiIjQxo0bC+wbFRUli8WSZ+rcuXMpVgwAAAAAwLXZPXTPnz9fCQkJSkxM1JYtWxQSEqIOHTro2LFj+fZftGiRjh49ap1++uknOTo6qmfPnqVcOQAAAAAAV2f30D1x4kQNGDBAcXFxCg4O1vTp0+Xm5qZZs2bl279y5cry9/e3TqtXr5abmxuhGwAAAABwwylnz41nZ2dr8+bNGjZsmLXNwcFB0dHRSk1NLdQ6Zs6cqQceeEAVKlQwq0wUkWW0xd4lFJuRaNi7BAAAAAA3EbuG7hMnTignJ0d+fn427X5+ftq9e/c1l9+4caN++uknzZw5s8A+WVlZysrKsr7OzMwsfsEAAAAAABSB3S8vvx4zZ85Uo0aN1LRp0wL7JCUlydPT0zoFBgaWYoUAAAAAgFuZXUO3t7e3HB0dlZ6ebtOenp4uf3//qy577tw5zZs3T/369btqv2HDhikjI8M6HT58+LrrBgAAAACgMOwaup2cnBQWFqbk5GRrW25urpKTk9W8efOrLrtgwQJlZWXp4Ycfvmo/Z2dneXh42EwAAAAAAJQGu97TLUkJCQmKjY1VeHi4mjZtqkmTJuncuXOKi4uTJMXExKhatWpKSkqyWW7mzJnq1q2bqlSpYo+yAQAAAAC4JruH7t69e+v48eMaOXKk0tLSFBoaqpUrV1oHVzt06JAcHGxPyO/Zs0ffffedvvzyS3uUDAAAAABAodg9dEtSfHy84uPj852XkpKSp61evXoyDB7tBAAAAAC4sZXp0csBAAAAALiREboBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJOUs3cBAAAAkCyjLfYuodiMRMPeJQDADYsz3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmMTuoXvq1KkKCgqSi4uLIiIitHHjxqv2P336tJ588kkFBATI2dlZdevW1fLly0upWgAAAAAACq+cPTc+f/58JSQkaPr06YqIiNCkSZPUoUMH7dmzR76+vnn6Z2dnq127dvL19dVnn32matWq6eDBg/Ly8ir94gEAAAAAuAa7hu6JEydqwIABiouLkyRNnz5dy5Yt06xZszR06NA8/WfNmqWTJ09q/fr1Kl++vCQpKCioNEsGAAAAAKDQ7HZ5eXZ2tjZv3qzo6Oj/FePgoOjoaKWmpua7zJIlS9S8eXM9+eST8vPzU8OGDTVu3Djl5OSUVtkAAAAAABSa3c50nzhxQjk5OfLz87Np9/Pz0+7du/Nd5rffftOaNWv00EMPafny5dq7d68GDhyoCxcuKDExMd9lsrKylJWVZX2dmZlZcjsBAAAAAMBV2H0gtaLIzc2Vr6+v3n33XYWFhal379568cUXNX369AKXSUpKkqenp3UKDAwsxYoBAAAAALcyu4Vub29vOTo6Kj093aY9PT1d/v7++S4TEBCgunXrytHR0drWoEEDpaWlKTs7O99lhg0bpoyMDOt0+PDhktsJAAAAAACuwm6h28nJSWFhYUpOTra25ebmKjk5Wc2bN893mZYtW2rv3r3Kzc21tv3yyy8KCAiQk5NTvss4OzvLw8PDZgIAAAAAoDTY9fLyhIQEzZgxQ++//7527dqlJ554QufOnbOOZh4TE6Nhw4ZZ+z/xxBM6efKkBg0apF9++UXLli3TuHHj9OSTT9prFwAAAAAAKJBdHxnWu3dvHT9+XCNHjlRaWppCQ0O1cuVK6+Bqhw4dkoPD/74XCAwM1KpVqzR48GA1btxY1apV06BBg/TCCy/YaxcAAAAAACiQXUO3JMXHxys+Pj7feSkpKXnamjdvru+//97kqgAAAAAAuH5lavRyAAAAAADKEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYJIbInRPnTpVQUFBcnFxUUREhDZu3Fhg3zlz5shisdhMLi4upVgtAAAAAACFY/fQPX/+fCUkJCgxMVFbtmxRSEiIOnTooGPHjhW4jIeHh44ePWqdDh48WIoVAwAAAABQOHYP3RMnTtSAAQMUFxen4OBgTZ8+XW5ubpo1a1aBy1gsFvn7+1snPz+/UqwYAAAAAIDCsWvozs7O1ubNmxUdHW1tc3BwUHR0tFJTUwtc7uzZs6pevboCAwN17733aufOnaVRLgAAAAAARWLX0H3ixAnl5OTkOVPt5+entLS0fJepV6+eZs2apf/+97/66KOPlJubqxYtWuj333/Pt39WVpYyMzNtJgAAAAAASoPdLy8vqubNmysmJkahoaGKjIzUokWL5OPjo3feeSff/klJSfL09LROgYGBpVwxAAAAAOBWZdfQ7e3tLUdHR6Wnp9u0p6eny9/fv1DrKF++vJo0aaK9e/fmO3/YsGHKyMiwTocPH77uugEAAAAAKAy7hm4nJyeFhYUpOTnZ2pabm6vk5GQ1b968UOvIycnRjz/+qICAgHznOzs7y8PDw2YCAAAAAKA0lLN3AQkJCYqNjVV4eLiaNm2qSZMm6dy5c4qLi5MkxcTEqFq1akpKSpIkjRkzRs2aNVPt2rV1+vRpvf766zp48KD69+9vz90AAAAAACAPu4fu3r176/jx4xo5cqTS0tIUGhqqlStXWgdXO3TokBwc/ndC/tSpUxowYIDS0tJUqVIlhYWFaf369QoODrbXLgAAAAAAkC+LYRiGvYsoTZmZmfL09FRGRsYNf6m5xWLvCoppVFktXDISb6nDAdeB47P0cXyisDg+Sx/HJwqL47P0cXyap7DZssyNXg4AAAAAQFlB6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMUiKhOzMzU4sXL9auXbtKYnUAAAAAANwUihW6e/XqpbfeekuS9Ndffyk8PFy9evVS48aNtXDhwhItEAAAAACAsqpYofubb75Rq1atJEmff/65DMPQ6dOn9eabb+o///lPiRYIAAAAAEBZVazQnZGRocqVK0uSVq5cqR49esjNzU2dO3fWr7/+WqIFAgAAAABQVhUrdAcGBio1NVXnzp3TypUr1b59e0nSqVOn5OLiUqIFAgAAAABQVpUrzkLPPPOMHnroIbm7u+tf//qXoqKiJF267LxRo0YlWR8AAAAAAGVWsUL3wIED1bRpUx0+fFjt2rWTg8OlE+Y1a9bknm4AAAAAAP6/YoVuSQoPD1fjxo21f/9+1apVS+XKlVPnzp1LsjYAAAAAAMq0Yt3Tff78efXr109ubm66/fbbdejQIUnSU089pVdeeaVECwQAAAAAoKwqVugeNmyYtm/frpSUFJuB06KjozV//vwSKw4AAAAAgLKsWJeXL168WPPnz1ezZs1ksVis7bfffrv27dtXYsUBAAAAAFCWFetM9/Hjx+Xr65un/dy5czYhHAAAAACAW1mxQnd4eLiWLVtmfX05aL/33ntq3rx5yVQGAAAAAEAZV6zLy8eNG6e7775bP//8sy5evKjJkyfr559/1vr16/X111+XdI0AAAAAAJRJxTrT/e9//1vbt2/XxYsX1ahRI3355Zfy9fVVamqqwsLCSrpGAAAAAADKpCKf6b5w4YIee+wxjRgxQjNmzDCjJgAAAAAAbgpFPtNdvnx5LVy40IxaAAAAAAC4qRTr8vJu3bpp8eLFJVwKAAAAAAA3l2INpFanTh2NGTNG69atU1hYmCpUqGAz/+mnny6R4gAAAAAAKMuKFbpnzpwpLy8vbd68WZs3b7aZZ7FYCN0AAAAAAKiYoXv//v0lXQcAAAAAADedYt3TfSXDMGQYRknUAgAAAADATaXYofuDDz5Qo0aN5OrqKldXVzVu3FgffvhhSdYGAAAAAECZVqzLyydOnKgRI0YoPj5eLVu2lCR99913evzxx3XixAkNHjy4RIsEAAAAAKAsKlbonjJliqZNm6aYmBhr2z333KPbb79do0aNInQDAAAAAKBiXl5+9OhRtWjRIk97ixYtdPTo0esuCgAAAACAm0GxQnft2rX16aef5mmfP3++6tSpc91FAQAAAABwMyjW5eWjR49W79699c0331jv6V63bp2Sk5PzDeMAAAAAANyKinWmu0ePHtqwYYO8vb21ePFiLV68WN7e3tq4caO6d+9e0jUCAAAAAFAmFetMtySFhYXpo48+KslaAAAAAAC4qRTrTPfy5cu1atWqPO2rVq3SihUrrrsoAAAAAABuBsUK3UOHDlVOTk6edsMwNHTo0OsuCgAAAACAm0GxQvevv/6q4ODgPO3169fX3r17r7soAAAAAABuBsUK3Z6envrtt9/ytO/du1cVKlS47qIAAAAAALgZFCt033vvvXrmmWe0b98+a9vevXv17LPP6p577imx4gAAAAAAKMuKFbpfe+01VahQQfXr11eNGjVUo0YN1a9fX1WqVNH48eNLukYAAAAAAMqkYl9evn79ei1btkwDBw7Us88+q7Vr12rNmjXy8vIq8vqmTp2qoKAgubi4KCIiQhs3bizUcvPmzZPFYlG3bt2KvE0AAAAAAMxWpNCdmpqqL774QpJksVjUvn17+fr6avz48erRo4f+7//+T1lZWUUqYP78+UpISFBiYqK2bNmikJAQdejQQceOHbvqcgcOHNBzzz2nVq1aFWl7AAAAAACUliKF7jFjxmjnzp3W1z/++KMGDBigdu3aaejQoVq6dKmSkpKKVMDEiRM1YMAAxcXFKTg4WNOnT5ebm5tmzZpV4DI5OTl66KGHNHr0aNWsWbNI2wMAAAAAoLQUKXRv27ZNbdu2tb6eN2+emjZtqhkzZighIUFvvvmmPv3000KvLzs7W5s3b1Z0dPT/CnJwUHR0tFJTUwtcbsyYMfL19VW/fv2KUj4AAAAAAKWqXFE6nzp1Sn5+ftbXX3/9te6++27r6zvvvFOHDx8u9PpOnDihnJwcm3VKkp+fn3bv3p3vMt99951mzpypbdu2FWobWVlZNpe8Z2ZmFro+AAAAAACuR5HOdPv5+Wn//v2SLp2l3rJli5o1a2adf+bMGZUvX75kK7zCmTNn9Mgjj2jGjBny9vYu1DJJSUny9PS0ToGBgabVBwAAAADAlYp0prtTp04aOnSoXn31VS1evFhubm42A5nt2LFDtWrVKvT6vL295ejoqPT0dJv29PR0+fv75+m/b98+HThwQF27drW25ebmXtqRcuW0Z8+ePNsfNmyYEhISrK8zMzMJ3gAAAACAUlGk0D127Fjdd999ioyMlLu7u95//305OTlZ58+aNUvt27cv9PqcnJwUFham5ORk62O/cnNzlZycrPj4+Dz969evrx9//NGm7aWXXtKZM2c0efLkfMO0s7OznJ2dC10TAAAAAAAlpUih29vbW998840yMjLk7u4uR0dHm/kLFiyQu7t7kQpISEhQbGyswsPD1bRpU02aNEnnzp1TXFycJCkmJkbVqlVTUlKSXFxc1LBhQ5vlLz8X/J/tAAAAAADYW5FC92Wenp75tleuXLnI6+rdu7eOHz+ukSNHKi0tTaGhoVq5cqV1cLVDhw7JwaFIt54DAAAAAHBDKFboLmnx8fH5Xk4uSSkpKVddds6cOSVfEAAAAAAAJYBTyAAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJjkhgjdU6dOVVBQkFxcXBQREaGNGzcW2HfRokUKDw+Xl5eXKlSooNDQUH344YelWC0AAAAAAIVj99A9f/58JSQkKDExUVu2bFFISIg6dOigY8eO5du/cuXKevHFF5WamqodO3YoLi5OcXFxWrVqVSlXDgAAAADA1dk9dE+cOFEDBgxQXFycgoODNX36dLm5uWnWrFn59o+KilL37t3VoEED1apVS4MGDVLjxo313XfflXLlAAAAAABcnV1Dd3Z2tjZv3qzo6Ghrm4ODg6Kjo5WamnrN5Q3DUHJysvbs2aO77rrLzFIBAAAAACiycvbc+IkTJ5STkyM/Pz+bdj8/P+3evbvA5TIyMlStWjVlZWXJ0dFRb7/9ttq1a5dv36ysLGVlZVlfZ2ZmlkzxAAAAAABcg11Dd3FVrFhR27Zt09mzZ5WcnKyEhATVrFlTUVFRefomJSVp9OjRpV8kAAAAAOCWZ9fQ7e3tLUdHR6Wnp9u0p6eny9/fv8DlHBwcVLt2bUlSaGiodu3apaSkpHxD97Bhw5SQkGB9nZmZqcDAwJLZAQAAAAAArsKu93Q7OTkpLCxMycnJ1rbc3FwlJyerefPmhV5Pbm6uzSXkV3J2dpaHh4fNBAAAAABAabD75eUJCQmKjY1VeHi4mjZtqkmTJuncuXOKi4uTJMXExKhatWpKSkqSdOly8fDwcNWqVUtZWVlavny5PvzwQ02bNs2euwEAAAAAQB52D929e/fW8ePHNXLkSKWlpSk0NFQrV660Dq526NAhOTj874T8uXPnNHDgQP3+++9ydXVV/fr19dFHH6l379722gUAAAAAAPJlMQzDsHcRpSkzM1Oenp7KyMi44S81t1jsXUExjSqrhUtG4i11OOA6cHyWPo5PFBbHZ+nj+ERhcXyWPo5P8xQ2W9r1nm4AAAAAAG5mhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATFLO3gUAAAAAAExisdi7guIxDHtXUGII3cCV+E8JAAAAQAni8nIAAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMwujlAAAAuD48/QMACsSZbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExyQ4TuqVOnKigoSC4uLoqIiNDGjRsL7Dtjxgy1atVKlSpVUqVKlRQdHX3V/gAAAAAA2IvdQ/f8+fOVkJCgxMREbdmyRSEhIerQoYOOHTuWb/+UlBT16dNHa9euVWpqqgIDA9W+fXv98ccfpVw5AAAAAABXZ/fQPXHiRA0YMEBxcXEKDg7W9OnT5ebmplmzZuXbf+7cuRo4cKBCQ0NVv359vffee8rNzVVycnIpVw4AAAAAwNXZNXRnZ2dr8+bNio6OtrY5ODgoOjpaqamphVrH+fPndeHCBVWuXNmsMgEAAAAAKJZy9tz4iRMnlJOTIz8/P5t2Pz8/7d69u1DreOGFF1S1alWb4H6lrKwsZWVlWV9nZmYWv2AAAAAAAIrA7peXX49XXnlF8+bN0+effy4XF5d8+yQlJcnT09M6BQYGlnKVAAAAAIBblV1Dt7e3txwdHZWenm7Tnp6eLn9//6suO378eL3yyiv68ssv1bhx4wL7DRs2TBkZGdbp8OHDJVI7AAAAAADXYtfQ7eTkpLCwMJtB0C4Pita8efMCl3vttdc0duxYrVy5UuHh4VfdhrOzszw8PGwmAAAAAABKg13v6ZakhIQExcbGKjw8XE2bNtWkSZN07tw5xcXFSZJiYmJUrVo1JSUlSZJeffVVjRw5Uh9//LGCgoKUlpYmSXJ3d5e7u7vd9gMAYDKLxd4VFI9h2LsCAABgR3YP3b1799bx48c1cuRIpaWlKTQ0VCtXrrQOrnbo0CE5OPzvhPy0adOUnZ2t+++/32Y9iYmJGjVqVGmWDgAAAADAVdk9dEtSfHy84uPj852XkpJi8/rAgQPmFwQAAAAAQAko06OXAwAAAABwIyN0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACaxe+ieOnWqgoKC5OLiooiICG3cuLHAvjt37lSPHj0UFBQki8WiSZMmlV6hAAAAAAAUkV1D9/z585WQkKDExERt2bJFISEh6tChg44dO5Zv//Pnz6tmzZp65ZVX5O/vX8rVAgAAAABQNHYN3RMnTtSAAQMUFxen4OBgTZ8+XW5ubpo1a1a+/e+88069/vrreuCBB+Ts7FzK1QIAAAAAUDR2C93Z2dnavHmzoqOj/1eMg4Oio6OVmppqr7IAAAAAACgx5ey14RMnTignJ0d+fn427X5+ftq9e3eJbScrK0tZWVnW15mZmSW2bgAAAAAArsbuA6mZLSkpSZ6entYpMDDQ3iUBAAAAAG4Rdgvd3t7ecnR0VHp6uk17enp6iQ6SNmzYMGVkZFinw4cPl9i6AQAAAAC4GruFbicnJ4WFhSk5Odnalpubq+TkZDVv3rzEtuPs7CwPDw+bCQAAAACA0mC3e7olKSEhQbGxsQoPD1fTpk01adIknTt3TnFxcZKkmJgYVatWTUlJSZIuDb72888/W//9xx9/aNu2bXJ3d1ft2rXtth8AAAAAAOTHrqG7d+/eOn78uEaOHKm0tDSFhoZq5cqV1sHVDh06JAeH/52MP3LkiJo0aWJ9PX78eI0fP16RkZFKSUkp7fIBAAAAALgqu4ZuSYqPj1d8fHy+8/4ZpIOCgmQYRilUBQAAAADA9bvpRy8HAAAAAMBeCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASW6I0D116lQFBQXJxcVFERER2rhx41X7L1iwQPXr15eLi4saNWqk5cuXl1KlAAAAAAAUnt1D9/z585WQkKDExERt2bJFISEh6tChg44dO5Zv//Xr16tPnz7q16+ftm7dqm7duqlbt2766aefSrlyAAAAAACuzu6he+LEiRowYIDi4uIUHBys6dOny83NTbNmzcq3/+TJk9WxY0cNGTJEDRo00NixY3XHHXforbfeKuXKAQAAAAC4OruG7uzsbG3evFnR0dHWNgcHB0VHRys1NTXfZVJTU236S1KHDh0K7A8AAAAAgL2Us+fGT5w4oZycHPn5+dm0+/n5affu3fkuk5aWlm//tLS0fPtnZWUpKyvL+jojI0OSlJmZeT2l42r+tncBxVdmfyr4eUZhcXyWPo5PFBbHZ+nj+ERhcXyWvjJwfF7OlIZhXLWfXUN3aUhKStLo0aPztAcGBtqhmlvEK/YuoPg87V1AcXmW2cpR2jg+Sx/HJwqL47P0cXyisDg+S18ZOj7PnDkjz6vUa9fQ7e3tLUdHR6Wnp9u0p6eny9/fP99l/P39i9R/2LBhSkhIsL7Ozc3VyZMnVaVKFVksluvcA5S2zMxMBQYG6vDhw/Lw8LB3OQCuwPEJ3Lg4PoEbF8dn2WUYhs6cOaOqVatetZ9dQ7eTk5PCwsKUnJysbt26SboUipOTkxUfH5/vMs2bN1dycrKeeeYZa9vq1avVvHnzfPs7OzvL2dnZps3Ly6skyocdeXh48J8ScIPi+ARuXByfwI2L47NsutoZ7svsfnl5QkKCYmNjFR4erqZNm2rSpEk6d+6c4uLiJEkxMTGqVq2akpKSJEmDBg1SZGSkJkyYoM6dO2vevHnatGmT3n33XXvuBgAAAAAAedg9dPfu3VvHjx/XyJEjlZaWptDQUK1cudI6WNqhQ4fk4PC/QdZbtGihjz/+WC+99JKGDx+uOnXqaPHixWrYsKG9dgEAAAAAgHzZPXRLUnx8fIGXk6ekpORp69mzp3r27GlyVbgROTs7KzExMc8tAwDsj+MTuHFxfAI3Lo7Pm5/FuNb45gAAAAAAoFgcrt0FAAAAAAAUB6EbAAAAAACTELqB65CSkiKLxaLTp0/buxQAhTBq1CiFhobauwzghhUVFWXzWFYApePKYy8oKEiTJk2yaz0oWTfEQGoAAAAAAOmHH35QhQoV7F0GShChGzes7OxsOTk52bsM4JaUk5Mji8Vi88hGAABgPh8fH3uXgBLGX1MoUH6XtoSGhmrUqFGSJIvFovfee0/du3eXm5ub6tSpoyVLllj7hoeHa/z48dbX3bp1U/ny5XX27FlJ0u+//y6LxaK9e/datzd27FjFxMTIw8ND//d//ydJeuGFF1S3bl25ubmpZs2aGjFihC5cuGBd7+XLRd955x0FBgbKzc1NvXr1UkZGhrVP37591a1bN40ePVo+Pj7y8PDQ448/ruzsbGuf3NxcJSUlqUaNGnJ1dVVISIg+++wzm/1fvny56tatK1dXV7Vu3VoHDhwo/hsMFNL1HouXb4NYtmyZGjduLBcXFzVr1kw//fSTtc+cOXPk5eWlJUuWKDg4WM7Ozjp06JBOnTqlmJgYVapUSW5ubrr77rv166+/2tSybt06RUVFyc3NTZUqVVKHDh106tQpSdc+rk6dOqWHHnpIPj4+cnV1VZ06dTR79mxJl754i4+PV0BAgFxcXFS9enUlJSVZlz19+rT69+9vPabbtGmj7du329T2yiuvyM/PTxUrVlS/fv30999/F/+DAG5An332mRo1aiRXV1dVqVJF0dHROnfuXKF+7507d04xMTFyd3dXQECAJkyYYMc9AW4d1zr2uLz85kPoxnUZPXq0evXqpR07dqhTp0566KGHdPLkSUlSZGSk9TnrhmHo22+/lZeXl7777jtJ0tdff61q1aqpdu3a1vWNHz9eISEh2rp1q0aMGCFJqlixoubMmaOff/5ZkydP1owZM/TGG2/Y1LF37159+umnWrp0qVauXKmtW7dq4MCBNn2Sk5O1a9cupaSk6JNPPtGiRYs0evRo6/ykpCR98MEHmj59unbu3KnBgwfr4Ycf1tdffy1JOnz4sO677z517dpV27ZtU//+/TV06NCSfUOBYrrasXjZkCFDNGHCBP3www/y8fFR165dbb7AOn/+vF599VW999572rlzp3x9fdW3b19t2rRJS5YsUWpqqgzDUKdOnazLbdu2TW3btlVwcLBSU1P13XffqWvXrsrJyZF07eNqxIgR+vnnn7VixQrt2rVL06ZNk7e3tyTpzTff1JIlS/Tpp59qz549mjt3roKCgqz19uzZU8eOHdOKFSu0efNm3XHHHWrbtq11vz/99FONGjVK48aN06ZNmxQQEKC3337btM8AKG1Hjx5Vnz599Oijj1p/v9133326/DTYa/3eGzJkiL7++mv997//1ZdffqmUlBRt2bLFXrsD3DI49m5BBlCA6tWrG2+88YZNW0hIiJGYmGgYhmFIMl566SXrvLNnzxqSjBUrVhiGYRhLliwxPD09jYsXLxrbtm0z/P39jUGDBhkvvPCCYRiG0b9/f+PBBx+02V63bt2uWdfrr79uhIWFWV8nJiYajo6Oxu+//25tW7FiheHg4GAcPXrUMAzDiI2NNSpXrmycO3fO2mfatGmGu7u7kZOTY/z999+Gm5ubsX79eptt9evXz+jTp49hGIYxbNgwIzg42Gb+Cy+8YEgyTp06dc26geK63mNx7dq1hiRj3rx51j5//vmn4erqasyfP98wDMOYPXu2IcnYtm2btc8vv/xiSDLWrVtnbTtx4oTh6upqfPrpp4ZhGEafPn2Mli1b5lt3YY6rrl27GnFxcfku/9RTTxlt2rQxcnNz88z79ttvDQ8PD+Pvv/+2aa9Vq5bxzjvvGIZhGM2bNzcGDhxoMz8iIsIICQnJd3tAWbN582ZDknHgwIE88671e+/MmTOGk5OT9Vg2jP/9vzBo0KDSKB+4JRXm2Mvv9z7KNu7pxnVp3Lix9d8VKlSQh4eHjh07Jklq1aqVzpw5o61bt2r9+vWKjIxUVFSUXnnlFUmXznQPGTLEZn3h4eF5tjF//ny9+eab2rdvn86ePauLFy/Kw8PDps+//vUvVatWzfq6efPmys3N1Z49e+Tv7y9JCgkJkZubm02fs2fP6vDhwzp79qzOnz+vdu3a2aw3OztbTZo0kSTt2rVLERERNvObN29euDcKMNnVjsXLrvx5rVy5surVq6ddu3ZZ25ycnGzWs2vXLpUrV87m575KlSo2y23btk09e/bMt6a9e/de87h64okn1KNHD23ZskXt27dXt27d1KJFC0mXbgtp166d6tWrp44dO6pLly5q3769JGn79u06e/asqlSpYrPuv/76S/v27bPW//jjj+d5D9auXZtvvUBZExISorZt26pRo0bq0KGD2rdvr/vvv1+VKlWyzi/o997p06eVnZ1tc3xf/n8BgHn27dvHsXcLInSjQA4ODtZL1C678lJUSSpfvrzNa4vFotzcXEmSl5eXQkJClJKSotTUVLVr10533XWXevfurV9++UW//vqrIiMjbZb/50iNqampeuihhzR69Gh16NBBnp6emjdvXonfd3b5PvNly5bZhHdJcnZ2LtFtAUV1vcdiYbm6uspisRR5mYIU5ri6++67dfDgQS1fvlyrV69W27Zt9eSTT2r8+PG64447tH//fq1YsUJfffWVevXqpejoaH322Wc6e/asAgICrLewXMnLy6tI+wCUVY6Ojlq9erXWr1+vL7/8UlOmTNGLL76oDRs22Ls0AMAVuKcbBfLx8dHRo0etrzMzM7V///4irSMyMlJr167VN998o6ioKFWuXFkNGjTQyy+/rICAANWtW/eqy69fv17Vq1fXiy++qPDwcNWpU0cHDx7M0+/QoUM6cuSI9fX3338vBwcHm28Nt2/frr/++sumj7u7uwIDA20Gjqpdu7bNFBgYKElq0KCBNm7caLPd77//vkjvB1AcJXEsSrY/r6dOndIvv/yiBg0aFNi/QYMGunjxos0f8H/++af27Nmj4OBgSZfOsCcnJ+e7fGGOq8v7Fxsbq48++kiTJk3Su+++a53n4eGh3r17a8aMGZo/f74WLlyokydP6o477lBaWprKlSuXZ92X7wlv0KBBnvDBMYubjcViUcuWLTV69Ght3bpVTk5O+vzzzyVd/fderVq1VL58eZtj5PL/CwDMw7F3a+JMNwrUpk0bzZkzR127dpWXl5dGjhwpR0fHIq0jKipKU6ZMkY+Pj+rXr29te+uttwq8JPVKderU0aFDhzRv3jzdeeedWrZsmfWPiSu5uLgoNjZW48ePV2Zmpp5++mn16tXLemm5dOmS1n79+umll17SgQMHlJiYqPj4eDk4OKhixYp67rnnNHjwYOXm5urf//63MjIytG7dOnl4eCg2NlaPP/64JkyYoCFDhqh///7avHmz5syZU6T3AyiOkjgWJWnMmDGqUqWK/Pz89OKLL8rb21vdunUrsH+dOnV07733asCAAXrnnXdUsWJFDR06VNWqVdO9994rSRo2bJgaNWqkgQMH6vHHH5eTk5PWrl2rnj17ytvb+5rH1ciRIxUWFqbbb79dWVlZ+uKLL6xfBEycOFEBAQFq0qSJHBwctGDBAvn7+8vLy0vR0dFq3ry5unXrptdee01169bVkSNHtGzZMnXv3l3h4eEaNGiQ+vbtq/DwcLVs2VJz587Vzp07VbNmzWJ9DsCNZsOGDUpOTlb79u3l6+urDRs26Pjx42rQoIF27Nhx1d977u7u6tevn4YMGaIqVarI19dXL774Io8JBEzGsXdrInSjQMOGDdP+/fvVpUsXeXp6auzYsUU+u9aqVSvl5ubaXEYeFRWlyZMnKyoq6prL33PPPRo8eLDi4+OVlZWlzp07a8SIEdZHJV1Wu3Zt3XffferUqZNOnjypLl265BmluG3btqpTp47uuusuZWVlqU+fPjbrGTt2rHx8fJSUlKTffvtNXl5euuOOOzR8+HBJl+4bX7hwoQYPHqwpU6aoadOmGjdunB599NEivSdAUZXEsShdenzWoEGD9Ouvvyo0NFRLly6Vk5PTVZeZPXu2Bg0apC5duig7O1t33XWXli9fbr2cvW7duvryyy81fPhwNW3aVK6uroqIiFCfPn0kXfu4cnJy0rBhw3TgwAG5urqqVatWmjdvnqRLTy547bXX9Ouvv8rR0VF33nmnli9fbv3DZPny5XrxxRcVFxen48ePy9/fX3fddZf8/PwkSb1799a+ffv0/PPP6++//1aPHj30xBNPaNWqVUV+74AbkYeHh7755htNmjRJmZmZql69uiZMmKC7775b8+fPv+bvvddff11nz55V165dVbFiRT377LM2j9sEYA6OvVuPxfjnjYJAGTNq1CgtXrxY27ZtK7BP3759dfr0aS1evLjU6gJuFCkpKWrdurVOnTrF/c7ALYLfewBw4+A6BgAAAAAATELoBgAAAADAJFxeDgAAAACASTjTDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAQJLUt29fdevWzd5lAABwUyF0AwBQivr27SuLxZJn6tixo71L0+TJkzVnzhx7lyFJslgsWrx4sb3LAADgupWzdwEAANxqOnbsqNmzZ9u0OTs726kaKScnRxaLRZ6ennarAQCAmxVnugEAKGXOzs7y9/e3mSpVqqSUlBQ5OTnp22+/tfZ97bXX5Ovrq/T0dElSVFSU4uPjFR8fL09PT3l7e2vEiBEyDMO6TFZWlp577jlVq1ZNFSpUUEREhFJSUqzz58yZIy8vLy1ZskTBwcFydnbWoUOH8lxeHhUVpaeeekrPPPOMKlWqJD8/P82YMUPnzp1TXFycKlasqNq1a2vFihU2+/fTTz/p7rvvlru7u/z8/PTII4/oxIkTNut9+umn9fzzz6ty5cry9/fXqFGjrPODgoIkSd27d5fFYrG+3r59u1q3bq2KFSvKw8NDYWFh2rRp03V+GgAAmIvQDQDADSIqKkrPPPOMHnnkEWVkZGjr1q0aMWKE3nvvPfn5+Vn7vf/++ypXrpw2btyoyZMna+LEiXrvvfes8+Pj45Wamqp58+Zpx44d6tmzpzp27Khff/3V2uf8+fN69dVX9d5772nnzp3y9fXNt6b3339f3t7e2rhxo5566ik98cQT6tmzp1q0aKEtW7aoffv2euSRR3T+/HlJ0unTp9WmTRs1adJEmzZt0sqVK5Wenq5evXrlWW+FChW0YcMGvfbaaxozZoxWr14tSfrhhx8kSbNnz9bRo0etrx966CHddttt+uGHH7R582YNHTpU5cuXL4F3HgAA81iMK78aBwAApurbt68++ugjubi42LQPHz5cw4cPV3Z2tiIiIlS3bl399NNPatmypd59911rv6ioKB07dkw7d+6UxWKRJA0dOlRLlizRzz//rEOHDqlmzZo6dOiQqlatal0uOjpaTZs21bhx4zRnzhzFxcVp27ZtCgkJsant9OnT1nupo6KilJOTYz3znpOTI09PT91333364IMPJElpaWkKCAhQamqqmjVrpv/85z/69ttvtWrVKut6f//9dwUGBmrPnj2qW7dunvVKUtOmTdWmTRu98sorki7d0/3555/bnHn38PDQlClTFBsbez0fAQAApYp7ugEAKGWtW7fWtGnTbNoqV64sSXJyctLcuXPVuHFjVa9eXW+88Uae5Zs1a2YN3JLUvHlzTZgwQTk5Ofrxxx+Vk5OjunXr2iyTlZWlKlWqWF87OTmpcePG16z1yj6Ojo6qUqWKGjVqZG27fAb+2LFjki5dAr527Vq5u7vnWde+ffusdf1z2wEBAdZ1FCQhIUH9+/fXhx9+qOjoaPXs2VO1atW65j4AAGBPhG4AAEpZhQoVVLt27QLnr1+/XpJ08uRJnTx5UhUqVCj0us+ePStHR0dt3rxZjo6ONvOuDMKurq42wb0g/7x822Kx2LRdXkdubq51+127dtWrr76aZ10BAQFXXe/ldRRk1KhRevDBB7Vs2TKtWLFCiYmJmjdvnrp3737N/QAAwF4I3QAA3ED27dunwYMHa8aMGZo/f75iY2P11VdfycHhf8OwbNiwwWaZ77//XnXq1JGjo6OaNGminJwcHTt2TK1atSrt8nXHHXdo4cKFCgoKUrlyxf8zo3z58srJycnTXrduXdWtW1eDBw9Wnz59NHv2bEI3AOCGxkBqAACUsqysLKWlpdlMJ06cUE5Ojh5++GF16NBBcXFxmj17tnbs2KEJEybYLH/o0CElJCRoz549+uSTTzRlyhQNGjRI0qVQ+tBDDykmJkaLFi3S/v37tXHjRiUlJWnZsmWm79uTTz6pkydPqk+fPvrhhx+0b98+rVq1SnFxcfmG6IIEBQUpOTlZaWlpOnXqlP766y/Fx8crJSVFBw8e1Lp16/TDDz+oQYMGJu4NAADXjzPdAACUspUrV9pcai1J9erV04MPPqiDBw/qiy++kHTpcux3331Xffr0Ufv27a2DnsXExOivv/5S06ZN5ejoqEGDBun//u//rOuaPXu2/vOf/+jZZ5/VH3/8IW9vbzVr1kxdunQxfd+qVq2qdevW6YUXXlD79u2VlZWl6tWrq2PHjjZn669lwoQJSkhI0IwZM1StWjX98ssv+vPPPxUTE6P09HR5e3vrvvvu0+jRo03cGwAArh+jlwMAUIZERUUpNDRUkyZNsncpAACgELi8HAAAAAAAkxC6AQAAAAAwCZeXAwAAAABgEs50AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGCS/wf+0sge4suHMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define the bar width and positions\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(experiments))\n",
    "\n",
    "# Plot each metric as a triplet of bars\n",
    "ax.bar(index, accuracies, bar_width, label='Accuracy', color='blue')\n",
    "ax.bar(index + bar_width, spds, bar_width, label='SPD', color='green')\n",
    "ax.bar(index + 2 * bar_width, dis, bar_width, label='DI', color='red')\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('Experiments')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison of Accuracy, SPD, and DI')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(experiments)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
