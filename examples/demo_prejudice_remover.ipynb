{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prejudice Remover: Fairness through Regularization\n",
    "\n",
    "The Prejudice Remover is an in-processing fairness algorithm that learns a classifier while removing direct and indirect prejudice by adding a regularization term to the objective function.\n",
    "\n",
    "This algorithm works by penalizing the mutual information between the sensitive attribute and the prediction, effectively reducing the influence of protected attributes on the model's decisions.\n",
    "\n",
    "Key features of the Prejudice Remover algorithm:\n",
    "- **Regularization-based approach**: Adds a fairness term to the loss function\n",
    "- **Tunable fairness parameter (eta)**: Controls the trade-off between accuracy and fairness\n",
    "- **Handles both direct and indirect discrimination**: Addresses both explicit and implicit biases\n",
    "- **Works with any differentiable model**: Can be applied to various neural network architectures\n",
    "\n",
    "In this demo, we'll explore how different values of the regularization parameter (eta) affect the fairness-accuracy trade-off."
   ],
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory of the project to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n"
   ],
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import openml\n",
    "\n",
    "from fairlib import DataFrame\n",
    "from fairlib.inprocessing import PrejudiceRemover\n",
    "from fairlib.metrics import statistical_parity_difference, disparate_impact\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading and Preparing the Adult Dataset\n",
    "We will use the Adult dataset from OpenML, which contains demographic information and predicts whether an individual earns more than $50K per year. We'll use 'sex' as our sensitive attribute."
   ],
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the Adult dataset from OpenML\n",
    "adult_dataset = openml.datasets.get_dataset(179)\n",
    "adult_X, _, _, _ = adult_dataset.get_data(dataset_format=\"dataframe\")\n",
    "\n",
    "# Rename the target column for clarity\n",
    "adult_X.rename(columns={'class': 'income'}, inplace=True)\n",
    "\n",
    "# Create a DataFrame object and specify target and sensitive attributes\n",
    "adult = DataFrame(adult_X)\n",
    "adult.targets = 'income'\n",
    "adult.sensitive = ['sex']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "adult.drop(columns=[\"fnlwgt\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_maps = {}\n",
    "for col in adult.columns:\n",
    "    if adult[col].dtype == 'object' or adult[col].dtype == 'category':\n",
    "        adult[col], uniques = pd.factorize(adult[col])\n",
    "        label_maps[col] = uniques\n",
    "\n",
    "print(f\"Dataset shape: {adult.shape}\")\n",
    "print(f\"Target column: {adult.targets}\")\n",
    "print(f\"Sensitive attributes: {adult.sensitive}\")\n",
    "\n",
    "adult.head()"
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Splitting the Dataset\n",
    "We'll split our data into training and testing sets to evaluate our models."
   ],
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:26:21.317304Z",
     "start_time": "2025-05-15T09:26:21.223978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into features and target\n",
    "X = adult.drop(columns=adult.targets)\n",
    "y = adult[adult.targets.pop()]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataFrames for training and testing\n",
    "train_df = DataFrame(pd.concat([X_train, y_train], axis=1))\n",
    "train_df.targets = adult.targets\n",
    "train_df.sensitive = adult.sensitive\n",
    "\n",
    "test_df = DataFrame(pd.concat([X_test, y_test], axis=1))\n",
    "test_df.targets = adult.targets\n",
    "test_df.sensitive = adult.sensitive\n",
    "\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Testing set shape: {test_df.shape}\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Split the data into features and target\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43madult\u001B[49m\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39madult\u001B[38;5;241m.\u001B[39mtargets)\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m adult[adult\u001B[38;5;241m.\u001B[39mtargets\u001B[38;5;241m.\u001B[39mpop()]\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Split into training and testing sets\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'adult' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Neural Network Model\n",
    "We'll define a simple neural network model to use with the Prejudice Remover algorithm."
   ],
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Get the number of features in our dataset\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "# Create a model instance\n",
    "model = SimpleNN(input_size)\n",
    "print(f\"Model created with input size: {input_size}\")"
   ],
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training and Evaluating Models with Different Eta Values\n",
    "Now we'll train multiple Prejudice Remover models with different eta values to see how this parameter affects the fairness-accuracy trade-off.\n",
    "- eta = 0: No fairness regularization (standard model)\n",
    "- eta > 0: Increasing values impose stronger fairness constraints"
   ],
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_and_evaluate(train_data, test_data, eta, epochs=200, batch_size=128):\n",
    "    model_copy = SimpleNN(input_size)\n",
    "    prejudice_remover = PrejudiceRemover(\n",
    "        model_copy,\n",
    "        loss=nn.BCELoss(),\n",
    "        eta=eta\n",
    "    )\n",
    "\n",
    "    prejudice_remover.fit(\n",
    "        train_data,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Convert from set to list before indexing\n",
    "    target_col = list(test_data.targets)[0]\n",
    "    sensitive_col = list(test_data.sensitive)[0]\n",
    "\n",
    "    # Prepare test data\n",
    "    X_test = test_data.drop(columns=target_col)\n",
    "    y_true = test_data[target_col].to_numpy()\n",
    "    sensitive = test_data[sensitive_col].to_numpy()\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = prejudice_remover.predict(X_test)\n",
    "    y_pred_binary = (y_pred > 0.5).float().numpy()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "\n",
    "    # Fairness metrics - use predictions as targets\n",
    "    spd = statistical_parity_difference(y_pred_binary, sensitive)\n",
    "    di  = disparate_impact(y_pred_binary, sensitive)\n",
    "\n",
    "    return {\n",
    "        'eta': eta,\n",
    "        'accuracy': accuracy,\n",
    "        'statistical_parity_difference': spd,\n",
    "        'disparate_impact': di\n",
    "    }\n",
    "\n",
    "\n",
    "# Define eta values to test\n",
    "eta_values = [0.0, 0.1, 0.3 ,0.5, 0.8]\n",
    "\n",
    "# Train and evaluate models with different eta values\n",
    "results = []\n",
    "for eta in eta_values:\n",
    "    print(f\"Training model with eta = {eta}...\")\n",
    "    result = train_and_evaluate(train_df, test_df, eta)\n",
    "    results.append(result)\n",
    "    print(f\"  Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"  Statistical Parity Difference: {result['statistical_parity_difference']}\")\n",
    "    print(f\"  Disparate Impact: {result['disparate_impact']}\")\n",
    "    print()\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
